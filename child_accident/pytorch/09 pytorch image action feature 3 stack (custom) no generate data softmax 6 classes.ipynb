{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class data():\n",
    "    def __init__(self, seq_length, batch_size):\n",
    "        np.random.seed(100)\n",
    "        self.seq_length = seq_length\n",
    "        self.acc_num = 334\n",
    "        self.no_acc_num = 392\n",
    "        self.split = 0.95\n",
    "        self.train_index = 0 \n",
    "        self.train_batch_size = batch_size\n",
    "        self.valid_index = 0\n",
    "        self.valid_batch_size = 12\n",
    "        self.read_annotation()\n",
    "        self.shuffle_data()\n",
    "        \n",
    "    def shuffle_data(self):\n",
    "        #img_range = np.arange(0,300-self.seq_length-60,60)\n",
    "        acc_list = np.arange(1,self.acc_num+1)\n",
    "        no_acc_list = np.arange(1,self.no_acc_num+1)\n",
    "        list1 = np.array(np.meshgrid(1,acc_list)).T.reshape(-1,2)\n",
    "        list2 = np.array(np.meshgrid(0,no_acc_list)).T.reshape(-1,2)\n",
    "        shuffle_list = np.concatenate([list1, list2], axis=0)\n",
    "        np.random.shuffle(shuffle_list)\n",
    "        self.train = shuffle_list[:int(shuffle_list.shape[0]*self.split)]\n",
    "        self.valid = shuffle_list[int(shuffle_list.shape[0]*self.split):] \n",
    "        \n",
    "    def read_annotation(self):\n",
    "        annotation_file = '/media/user/Hard_Disk/Dataset/child_accident_2/annotation/accident_frame.txt'\n",
    "        w = open(annotation_file, \"r\")\n",
    "        ann = w.read()\n",
    "        annotation_data = []\n",
    "        for i in ann.split(\"\\n\"):\n",
    "            b = i.split(\" \")\n",
    "            if (len(b) > 1):\n",
    "                annotation_data.append(b[1])\n",
    "        self.annotation = np.array(annotation_data).astype(\"int32\")\n",
    "        \n",
    "    def read_data(self, is_accident, dir_index):\n",
    "        data = []\n",
    "        label = []\n",
    "        range_start = 150 - self.seq_length\n",
    "        range_end = 150\n",
    "        img_path = '/media/user/Hard_Disk/Dataset/child_accident_2/image feature/' \n",
    "        act_path = '/media/user/Hard_Disk/Dataset/child_accident_2/action feature/' \n",
    "        if (is_accident):\n",
    "            acc_dir = \"accident/\"\n",
    "            accident_frame = self.annotation[dir_index-1]\n",
    "            if (accident_frame > 150 and accident_frame <= 180):\n",
    "                label.append(np.array([1,0,0,0,0,0]))\n",
    "            elif (accident_frame > 180 and accident_frame <= 210):\n",
    "                label.append(np.array([0,1,0,0,0,0]))\n",
    "            elif (accident_frame > 210 and accident_frame <= 240):\n",
    "                label.append(np.array([0,0,1,0,0,0]))\n",
    "            elif (accident_frame > 240 and accident_frame <= 270):\n",
    "                label.append(np.array([0,0,0,1,0,0]))\n",
    "            elif (accident_frame > 270 and accident_frame <=300):\n",
    "                label.append(np.array([0,0,0,0,1,0]))\n",
    "            else:\n",
    "                label.append(np.array([0,0,0,0,0,1]))\n",
    "        else:\n",
    "            acc_dir = \"no_accident/\"\n",
    "            \n",
    "            label.append(np.array([0,0,0,0,0,1]))\n",
    "            \n",
    "        dir_name = \"%04d\"%dir_index\n",
    "        img_npy = []\n",
    "        act_npy = []\n",
    "        for j in range(range_start, range_end):\n",
    "            \n",
    "            img_feature = np.load(img_path + acc_dir + dir_name + \"/\" + str(j) + \".npy\")\n",
    "            img_npy.append(img_feature)\n",
    "            act_feature = np.load(act_path + acc_dir + dir_name + \"/\" + str(j) + \".npy\")\n",
    "            act_npy.append(act_feature)\n",
    "        \n",
    "            \n",
    "        return np.array(img_npy), np.array(act_npy) ,np.array(label)\n",
    "        \n",
    "    def next_batch(self, mode=\"train\"):\n",
    "        batch_img = []\n",
    "        batch_act = []\n",
    "        batch_y = []\n",
    "        if (mode == \"valid\"):\n",
    "            batch_size = self.valid_batch_size\n",
    "        elif (mode == \"train\"):\n",
    "            batch_size = self.train_batch_size\n",
    "        for i in range(batch_size):\n",
    "            if (mode == \"train\"):\n",
    "                img, act, label = self.read_data(self.train[self.train_index+i][0], self.train[self.train_index+i][1])\n",
    "            elif (mode == \"valid\"):\n",
    "                img, act, label = self.read_data(self.valid[self.valid_index+i][0], self.valid[self.valid_index+i][1])\n",
    "            batch_img.append(img)\n",
    "            batch_act.append(act)\n",
    "            batch_y.append(label)\n",
    "        if (mode == \"valid\"):\n",
    "            self.valid_index += self.valid_batch_size\n",
    "        elif (mode == \"train\"):\n",
    "            self.train_index += self.train_batch_size\n",
    "        return np.array(batch_img), np.array(batch_act), np.squeeze(np.array(batch_y))\n",
    "    \n",
    "    def has_next(self, mode=\"train\"):\n",
    "        if (mode == \"train\"):\n",
    "            if (self.train_index + self.train_batch_size >= self.train.shape[0]):\n",
    "                return False\n",
    "        elif (mode == \"valid\"):\n",
    "            if (self.valid_index + self.valid_batch_size >= self.valid.shape[0]):\n",
    "                return False\n",
    "        return True\n",
    "    def display_shape(self):\n",
    "        print(\"train shape:\",self.train.shape, \" valid shape:\",self.valid.shape)\n",
    "        \n",
    "    def reset_batch(self, mode=\"train\"):\n",
    "        if (mode == \"train\"):\n",
    "            self.train_index = 0\n",
    "            np.random.shuffle(self.train)\n",
    "        elif (mode == \"valid\"):\n",
    "            self.valid_index = 0\n",
    "        \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recurrent neural network (many-to-one)\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, img_input_size, act_input_size, hidden_size, embedding_size, embedding_size2, num_layers, num_classes):\n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.img = nn.Sequential(\n",
    "            nn.Linear(img_input_size, embedding_size),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(embedding_size, embedding_size2)\n",
    "        )\n",
    "        self.act = nn.Sequential(\n",
    "            nn.Linear(act_input_size, embedding_size),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(embedding_size, embedding_size2)\n",
    "        )\n",
    "            \n",
    "        \n",
    "        self.img_fc1 = nn.Linear(img_input_size, embedding_size)\n",
    "        self.act_fc1 = nn.Linear(act_input_size, embedding_size)\n",
    "        self.img_fc2 = nn.Linear(embedding_size, embedding_size2)\n",
    "        self.act_fc2 = nn.Linear(embedding_size, embedding_size2)\n",
    "        self.lstm1 = nn.LSTM(embedding_size2*2, hidden_size, num_layers,dropout=0.25, batch_first=True)\n",
    "        self.lstm2 = nn.LSTM(embedding_size2*2, hidden_size, num_layers,dropout=0.25, batch_first=True)\n",
    "        self.lstm3 = nn.LSTM(embedding_size2*2, hidden_size, num_layers,dropout=0.25, batch_first=True)\n",
    "        self.st3_state_h = nn.Linear(hidden_size*3, hidden_size)\n",
    "        self.st3_state_c = nn.Linear(hidden_size*3, hidden_size)\n",
    "        self.st2_state_h = nn.Linear(hidden_size*2, hidden_size)\n",
    "        self.st2_state_c = nn.Linear(hidden_size*2, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "    \n",
    "    def forward(self, x, y):\n",
    "        # Set initial hidden and cell states \n",
    "        x1 = self.img_fc1(x)\n",
    "        x1 = self.img_fc2(x1)\n",
    "        x2 = self.act_fc1(y)\n",
    "        x2 = self.act_fc2(x2)\n",
    "#         x1 = self.img(x)\n",
    "#         x = self.act(y)\n",
    "        x = torch.cat((x1, x2), 2)\n",
    "#         print(x.shape)\n",
    "        \n",
    "        st1_h = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
    "        st1_c = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        \n",
    "        st2_h = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
    "        st2_c = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        \n",
    "        st3_h = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
    "        st3_c = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        \n",
    "        \n",
    "        for i in range(x.size(1)):\n",
    "        # Forward propagate LSTM\n",
    "            stack1_out, (st1_h, st1_c) = self.lstm1(x[:,i].unsqueeze(1), (st1_h, st1_c))  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "            stack2_out, (st2_h, st2_c) = self.lstm2(x[:,int(i/10)].unsqueeze(1), (st2_h, st2_c))\n",
    "            stack3_out, (st3_h, st3_c) = self.lstm3(x[:,int(i/20)].unsqueeze(1), (st3_h, st3_c))\n",
    "           \n",
    "            \n",
    "            st3_h = torch.cat((st1_h, st2_h, st3_h), 2)\n",
    "            st3_h = self.st3_state_h(st3_h)\n",
    "            \n",
    "            st3_c = torch.cat((st1_c, st2_c, st3_c), 2)\n",
    "            st3_c = self.st3_state_c(st3_c)\n",
    "            \n",
    "            \n",
    "            st2_h = torch.cat((st1_h, st2_h), 2)\n",
    "            st2_h = self.st2_state_h(st2_h)\n",
    "            \n",
    "            st2_c = torch.cat((st1_c, st2_c), 2)\n",
    "            st2_c = self.st2_state_c(st2_c)\n",
    "            \n",
    "            \n",
    "        \n",
    "        # Decode the hidden state of the last time step\n",
    "        \n",
    "        out = self.fc2(stack3_out[:,-1,:])\n",
    "        \n",
    "#         out = self.fc2(out[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.5/site-packages/torch/nn/modules/rnn.py:38: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.25 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    }
   ],
   "source": [
    "model = RNN(img_input_size=20*4096, act_input_size=1024, hidden_size=1024, embedding_size=1024, embedding_size2=512, num_layers=1, num_classes=6).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.from_numpy(np.array([1,1,1,1,1,0.5])).type(torch.FloatTensor).to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight=w)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (689, 2)  valid shape: (37, 2)\n"
     ]
    }
   ],
   "source": [
    "sequence_length = 100\n",
    "num_epochs = 20\n",
    "train_data = data(seq_length=sequence_length, batch_size=50)\n",
    "train_data.display_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out of memory\n",
    "def test():\n",
    "    model = torch.load('pytorch - 06/model-90.ckpt')\n",
    "    while(train_data.has_next(\"valid\")):\n",
    "        img, act, labels = train_data.next_batch(\"valid\")\n",
    "        labels = torch.from_numpy(labels).to(device)\n",
    "        img = torch.from_numpy(img.reshape(-1, sequence_length, 20*4096)).to(device)\n",
    "        act = torch.from_numpy(np.squeeze(act)).to(device)\n",
    "        outputs = model(img, act)\n",
    "        outputs = F.softmax(outputs)\n",
    "        predict = torch.max(outputs, 1)[1]\n",
    "        target = torch.max(labels, 1)[1]\n",
    "        recall(predict, target)\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric(pred, y):\n",
    "    pred = np.reshape(np.array(pred.cpu().numpy()), (-1,1))\n",
    "    y = np.reshape(np.array(y.cpu().numpy()), (-1, 1))\n",
    "    print(pred.reshape(1,-1))\n",
    "    print(y.reshape(1,-1))\n",
    "    print(\"=========================================\")\n",
    "    print(\"precision\")\n",
    "    print(metrics.precision_score(y, pred, average='macro'))\n",
    "    \n",
    "    print(\"Accuracy\")\n",
    "    print(metrics.accuracy_score(y, pred))\n",
    "    \n",
    "    print(\"Recall\")\n",
    "    print(metrics.recall_score(y, pred, average='macro'))\n",
    "    \n",
    "    print(\"F1_score\")\n",
    "    print(metrics.f1_score(y, pred, average='weighted'))\n",
    "    \n",
    "#     print(\"roc_auc_score\")\n",
    "#     fpr, tpr, thresholds = metrics.roc_curve(y, pred)\n",
    "#     roc_auc = metrics.auc(fpr, tpr)\n",
    "#     plt.title('Receiver Operating Characteristic')\n",
    "#     plt.plot(fpr, tpr, 'b',\n",
    "#     label='AUC = %0.2f'% roc_auc)\n",
    "#     plt.legend(loc='lower right')\n",
    "#     plt.plot([0,1],[0,1],'r--')\n",
    "#     plt.xlim([0,1.0])\n",
    "#     plt.ylim([0,1.0])\n",
    "#     plt.ylabel('True Positive Rate')\n",
    "#     plt.xlabel('False Positive Rate')\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(model):\n",
    "    with torch.no_grad():\n",
    "        i = 0\n",
    "        acc = 0\n",
    "        while(train_data.has_next(\"valid\")):\n",
    "            img, act, labels = train_data.next_batch(\"valid\")\n",
    "            labels = torch.from_numpy(labels).to(device)\n",
    "            img = torch.from_numpy(img.reshape(-1, sequence_length, 20*4096)).to(device)\n",
    "            act = torch.from_numpy(np.squeeze(act)).to(device)\n",
    "            outputs = model(img, act)\n",
    "            outputs = F.softmax(outputs)\n",
    "            predict = torch.max(outputs, 1)[1]\n",
    "            target = torch.max(labels, 1)[1]\n",
    "            loss = criterion(outputs, target)\n",
    "            correct = (predict == target).squeeze()\n",
    "            acc += torch.nonzero(correct).size(0) / predict.shape[0]\n",
    "            i += 1\n",
    "            metric(predict, target)\n",
    "        train_data.reset_batch(\"valid\")\n",
    "        print(\"validation accuracy:\",acc/i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:16: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Step 5, Loss: 1.6190\n",
      "precision\n",
      "0.09999999999999999\n",
      "Accuracy\n",
      "0.6\n",
      "Recall\n",
      "0.16666666666666666\n",
      "F1_score\n",
      "0.44999999999999996\n",
      "====================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/user/.local/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Step 10, Loss: 1.6131\n",
      "precision\n",
      "0.15\n",
      "Accuracy\n",
      "0.6\n",
      "Recall\n",
      "0.25\n",
      "F1_score\n",
      "0.44999999999999996\n",
      "====================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:11: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5 5 5 5 5 5 5 5 5 5 5 5]]\n",
      "[[5 3 0 2 2 5 5 5 4 5 5 2]]\n",
      "=========================================\n",
      "precision\n",
      "0.1\n",
      "Accuracy\n",
      "0.5\n",
      "Recall\n",
      "0.2\n",
      "F1_score\n",
      "0.3333333333333333\n",
      "[[5 5 5 5 5 5 5 5 5 5 5 5]]\n",
      "[[5 4 5 5 3 5 2 5 5 5 1 1]]\n",
      "=========================================\n",
      "precision\n",
      "0.11666666666666667\n",
      "Accuracy\n",
      "0.5833333333333334\n",
      "Recall\n",
      "0.2\n",
      "F1_score\n",
      "0.4298245614035088\n",
      "[[5 5 5 5 5 5 5 5 5 5 5 5]]\n",
      "[[5 5 5 2 3 5 4 5 5 2 5 2]]\n",
      "=========================================\n",
      "precision\n",
      "0.14583333333333334\n",
      "Accuracy\n",
      "0.5833333333333334\n",
      "Recall\n",
      "0.25\n",
      "F1_score\n",
      "0.4298245614035088\n",
      "validation accuracy: 0.5555555555555557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.5/site-packages/torch/serialization.py:193: UserWarning: Couldn't retrieve source code for container of type RNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1\n",
      "Epoch [2/20], Step 5, Loss: 1.6865\n",
      "precision\n",
      "0.08666666666666667\n",
      "Accuracy\n",
      "0.52\n",
      "Recall\n",
      "0.16666666666666666\n",
      "F1_score\n",
      "0.35578947368421054\n",
      "====================================\n",
      "Epoch [2/20], Step 10, Loss: 1.7085\n",
      "precision\n",
      "0.092\n",
      "Accuracy\n",
      "0.46\n",
      "Recall\n",
      "0.2\n",
      "F1_score\n",
      "0.28986301369863016\n",
      "====================================\n",
      "epoch: 2\n",
      "Epoch [3/20], Step 5, Loss: 1.5936\n",
      "precision\n",
      "0.09999999999999999\n",
      "Accuracy\n",
      "0.6\n",
      "Recall\n",
      "0.16666666666666666\n",
      "F1_score\n",
      "0.44999999999999996\n",
      "====================================\n",
      "Epoch [3/20], Step 10, Loss: 1.7005\n",
      "precision\n",
      "0.08\n",
      "Accuracy\n",
      "0.48\n",
      "Recall\n",
      "0.16666666666666666\n",
      "F1_score\n",
      "0.3113513513513514\n",
      "====================================\n",
      "epoch: 3\n",
      "Epoch [4/20], Step 5, Loss: 1.7094\n",
      "precision\n",
      "0.08\n",
      "Accuracy\n",
      "0.48\n",
      "Recall\n",
      "0.16666666666666666\n",
      "F1_score\n",
      "0.3113513513513514\n",
      "====================================\n",
      "Epoch [4/20], Step 10, Loss: 1.6990\n",
      "precision\n",
      "0.08333333333333333\n",
      "Accuracy\n",
      "0.5\n",
      "Recall\n",
      "0.16666666666666666\n",
      "F1_score\n",
      "0.33333333333333326\n",
      "====================================\n",
      "epoch: 4\n",
      "Epoch [5/20], Step 5, Loss: 1.6248\n",
      "precision\n",
      "0.11599999999999999\n",
      "Accuracy\n",
      "0.58\n",
      "Recall\n",
      "0.2\n",
      "F1_score\n",
      "0.42582278481012653\n",
      "====================================\n",
      "Epoch [5/20], Step 10, Loss: 1.6090\n",
      "precision\n",
      "0.09666666666666666\n",
      "Accuracy\n",
      "0.58\n",
      "Recall\n",
      "0.16666666666666666\n",
      "F1_score\n",
      "0.42582278481012653\n",
      "====================================\n",
      "epoch: 5\n",
      "Epoch [6/20], Step 5, Loss: 1.6256\n",
      "precision\n",
      "0.09333333333333334\n",
      "Accuracy\n",
      "0.56\n",
      "Recall\n",
      "0.16666666666666666\n",
      "F1_score\n",
      "0.40205128205128204\n",
      "====================================\n",
      "Epoch [6/20], Step 10, Loss: 1.5983\n",
      "precision\n",
      "0.11200000000000002\n",
      "Accuracy\n",
      "0.56\n",
      "Recall\n",
      "0.2\n",
      "F1_score\n",
      "0.40205128205128204\n",
      "====================================\n",
      "epoch: 6\n",
      "Epoch [7/20], Step 5, Loss: 1.6797\n",
      "precision\n",
      "0.08\n",
      "Accuracy\n",
      "0.48\n",
      "Recall\n",
      "0.16666666666666666\n",
      "F1_score\n",
      "0.3113513513513514\n",
      "====================================\n",
      "Epoch [7/20], Step 10, Loss: 1.5922\n",
      "precision\n",
      "0.2569444444444444\n",
      "Accuracy\n",
      "0.56\n",
      "Recall\n",
      "0.19444444444444445\n",
      "F1_score\n",
      "0.43397683397683395\n",
      "====================================\n",
      "epoch: 7\n",
      "Epoch [8/20], Step 5, Loss: 1.6178\n",
      "precision\n",
      "0.12962962962962962\n",
      "Accuracy\n",
      "0.54\n",
      "Recall\n",
      "0.18132716049382713\n",
      "F1_score\n",
      "0.41461538461538455\n",
      "====================================\n",
      "Epoch [8/20], Step 10, Loss: 1.5761\n",
      "precision\n",
      "0.23216783216783216\n",
      "Accuracy\n",
      "0.6\n",
      "Recall\n",
      "0.292\n",
      "F1_score\n",
      "0.5002173913043478\n",
      "====================================\n",
      "epoch: 8\n",
      "Epoch [9/20], Step 5, Loss: 1.5724\n",
      "precision\n",
      "0.17973856209150327\n",
      "Accuracy\n",
      "0.58\n",
      "Recall\n",
      "0.28163580246913583\n",
      "F1_score\n",
      "0.4856\n",
      "====================================\n",
      "Epoch [9/20], Step 10, Loss: 1.5719\n",
      "precision\n",
      "0.17570009033423664\n",
      "Accuracy\n",
      "0.58\n",
      "Recall\n",
      "0.22839506172839505\n",
      "F1_score\n",
      "0.4770588235294118\n",
      "====================================\n",
      "epoch: 9\n",
      "Epoch [10/20], Step 5, Loss: 1.5979\n",
      "precision\n",
      "0.17091114883984151\n",
      "Accuracy\n",
      "0.56\n",
      "Recall\n",
      "0.2786596119929453\n",
      "F1_score\n",
      "0.4742705570291777\n",
      "====================================\n",
      "Epoch [10/20], Step 10, Loss: 1.5335\n",
      "precision\n",
      "0.2031746031746032\n",
      "Accuracy\n",
      "0.64\n",
      "Recall\n",
      "0.3081481481481481\n",
      "F1_score\n",
      "0.52\n",
      "====================================\n",
      "epoch: 10\n",
      "Epoch [11/20], Step 5, Loss: 1.4285\n",
      "precision\n",
      "0.2873015873015873\n",
      "Accuracy\n",
      "0.72\n",
      "Recall\n",
      "0.3666666666666667\n",
      "F1_score\n",
      "0.6207444168734491\n",
      "====================================\n",
      "Epoch [11/20], Step 10, Loss: 1.4584\n",
      "precision\n",
      "0.3075757575757576\n",
      "Accuracy\n",
      "0.72\n",
      "Recall\n",
      "0.3666666666666667\n",
      "F1_score\n",
      "0.6125333333333333\n",
      "====================================\n",
      "[[5 5 5 5 5 5 5 5 5 5 3 5]]\n",
      "[[5 3 0 2 2 5 5 5 4 5 5 2]]\n",
      "=========================================\n",
      "precision\n",
      "0.09090909090909091\n",
      "Accuracy\n",
      "0.4166666666666667\n",
      "Recall\n",
      "0.16666666666666669\n",
      "F1_score\n",
      "0.29411764705882354\n",
      "[[5 5 5 5 3 5 5 5 5 3 5 3]]\n",
      "[[5 4 5 5 3 5 2 5 5 5 1 1]]\n",
      "=========================================\n",
      "precision\n",
      "0.2\n",
      "Accuracy\n",
      "0.5833333333333334\n",
      "Recall\n",
      "0.37142857142857144\n",
      "F1_score\n",
      "0.4791666666666667\n",
      "[[3 5 5 5 5 5 5 5 5 5 5 5]]\n",
      "[[5 5 5 2 3 5 4 5 5 2 5 2]]\n",
      "=========================================\n",
      "precision\n",
      "0.13636363636363635\n",
      "Accuracy\n",
      "0.5\n",
      "Recall\n",
      "0.21428571428571427\n",
      "F1_score\n",
      "0.38888888888888884\n",
      "validation accuracy: 0.5\n",
      "epoch: 11\n",
      "Epoch [12/20], Step 5, Loss: 1.4881\n",
      "precision\n",
      "0.23976608187134504\n",
      "Accuracy\n",
      "0.66\n",
      "Recall\n",
      "0.3181818181818182\n",
      "F1_score\n",
      "0.5381895937277263\n",
      "====================================\n",
      "Epoch [12/20], Step 10, Loss: 1.5994\n",
      "precision\n",
      "0.2624113475177305\n",
      "Accuracy\n",
      "0.6\n",
      "Recall\n",
      "0.26666666666666666\n",
      "F1_score\n",
      "0.4690540540540541\n",
      "====================================\n",
      "epoch: 12\n",
      "Epoch [13/20], Step 5, Loss: 1.4424\n",
      "precision\n",
      "0.2851851851851852\n",
      "Accuracy\n",
      "0.74\n",
      "Recall\n",
      "0.3333333333333333\n",
      "F1_score\n",
      "0.6319480519480519\n",
      "====================================\n",
      "Epoch [13/20], Step 10, Loss: 1.4777\n",
      "precision\n",
      "0.23888888888888887\n",
      "Accuracy\n",
      "0.64\n",
      "Recall\n",
      "0.3655172413793103\n",
      "F1_score\n",
      "0.5548549810844894\n",
      "====================================\n",
      "epoch: 13\n",
      "Epoch [14/20], Step 5, Loss: 1.4408\n",
      "precision\n",
      "0.3130952380952381\n",
      "Accuracy\n",
      "0.72\n",
      "Recall\n",
      "0.3555555555555555\n",
      "F1_score\n",
      "0.6220381110190556\n",
      "====================================\n",
      "Epoch [14/20], Step 10, Loss: 1.5724\n",
      "precision\n",
      "0.17585784313725492\n",
      "Accuracy\n",
      "0.56\n",
      "Recall\n",
      "0.30666666666666664\n",
      "F1_score\n",
      "0.44114959469417836\n",
      "====================================\n",
      "epoch: 14\n",
      "Epoch [15/20], Step 5, Loss: 1.4479\n",
      "precision\n",
      "0.3173234811165846\n",
      "Accuracy\n",
      "0.66\n",
      "Recall\n",
      "0.4212962962962963\n",
      "F1_score\n",
      "0.5890259740259741\n",
      "====================================\n",
      "Epoch [15/20], Step 10, Loss: 1.5954\n",
      "precision\n",
      "0.19015356820234866\n",
      "Accuracy\n",
      "0.58\n",
      "Recall\n",
      "0.3055555555555556\n",
      "F1_score\n",
      "0.4344615384615384\n",
      "====================================\n",
      "epoch: 15\n",
      "Epoch [16/20], Step 5, Loss: 1.4395\n",
      "precision\n",
      "0.22023809523809523\n",
      "Accuracy\n",
      "0.7\n",
      "Recall\n",
      "0.3273809523809524\n",
      "F1_score\n",
      "0.5888636363636363\n",
      "====================================\n",
      "Epoch [16/20], Step 10, Loss: 1.3319\n",
      "precision\n",
      "0.4199561403508772\n",
      "Accuracy\n",
      "0.8\n",
      "Recall\n",
      "0.46153846153846156\n",
      "F1_score\n",
      "0.7308895522388059\n",
      "====================================\n",
      "epoch: 16\n",
      "Epoch [17/20], Step 5, Loss: 1.3629\n",
      "precision\n",
      "0.2865079365079365\n",
      "Accuracy\n",
      "0.78\n",
      "Recall\n",
      "0.4\n",
      "F1_score\n",
      "0.6900949796472184\n",
      "====================================\n",
      "Epoch [17/20], Step 10, Loss: 1.3882\n",
      "precision\n",
      "0.29930069930069936\n",
      "Accuracy\n",
      "0.76\n",
      "Recall\n",
      "0.4\n",
      "F1_score\n",
      "0.6564759725400457\n",
      "====================================\n",
      "epoch: 17\n",
      "Epoch [18/20], Step 5, Loss: 1.4983\n",
      "precision\n",
      "0.25138427464008856\n",
      "Accuracy\n",
      "0.68\n",
      "Recall\n",
      "0.27777777777777773\n",
      "F1_score\n",
      "0.5766901408450704\n",
      "====================================\n",
      "Epoch [18/20], Step 10, Loss: 1.2759\n",
      "precision\n",
      "0.3150793650793651\n",
      "Accuracy\n",
      "0.82\n",
      "Recall\n",
      "0.36969696969696975\n",
      "F1_score\n",
      "0.7690434782608696\n",
      "====================================\n",
      "epoch: 18\n",
      "Epoch [19/20], Step 5, Loss: 1.4551\n",
      "precision\n",
      "0.2631578947368421\n",
      "Accuracy\n",
      "0.68\n",
      "Recall\n",
      "0.30952380952380953\n",
      "F1_score\n",
      "0.5811282051282051\n",
      "====================================\n",
      "Epoch [19/20], Step 10, Loss: 1.4683\n",
      "precision\n",
      "0.25252525252525254\n",
      "Accuracy\n",
      "0.7\n",
      "Recall\n",
      "0.3055555555555556\n",
      "F1_score\n",
      "0.5864864864864865\n",
      "====================================\n",
      "epoch: 19\n",
      "Epoch [20/20], Step 5, Loss: 1.5264\n",
      "precision\n",
      "0.19565217391304346\n",
      "Accuracy\n",
      "0.66\n",
      "Recall\n",
      "0.27777777777777773\n",
      "F1_score\n",
      "0.5335064935064936\n",
      "====================================\n",
      "Epoch [20/20], Step 10, Loss: 1.4439\n",
      "precision\n",
      "0.2267156862745098\n",
      "Accuracy\n",
      "0.7\n",
      "Recall\n",
      "0.3333333333333333\n",
      "F1_score\n",
      "0.577574967405476\n",
      "====================================\n",
      "epoch: 20\n",
      "Epoch [21/20], Step 5, Loss: 1.5176\n",
      "precision\n",
      "0.21637426900584797\n",
      "Accuracy\n",
      "0.64\n",
      "Recall\n",
      "0.3\n",
      "F1_score\n",
      "0.5170674486803519\n",
      "====================================\n",
      "Epoch [21/20], Step 10, Loss: 1.4459\n",
      "precision\n",
      "0.22718253968253968\n",
      "Accuracy\n",
      "0.72\n",
      "Recall\n",
      "0.3333333333333333\n",
      "F1_score\n",
      "0.6034984193888304\n",
      "====================================\n",
      "[[5 5 5 5 5 5 5 5 5 3 3 5]]\n",
      "[[5 3 0 2 2 5 5 5 4 5 5 2]]\n",
      "=========================================\n",
      "precision\n",
      "0.08\n",
      "Accuracy\n",
      "0.3333333333333333\n",
      "Recall\n",
      "0.13333333333333333\n",
      "F1_score\n",
      "0.25\n",
      "[[5 5 5 5 3 5 5 5 5 3 5 3]]\n",
      "[[5 4 5 5 3 5 2 5 5 5 1 1]]\n",
      "=========================================\n",
      "precision\n",
      "0.2\n",
      "Accuracy\n",
      "0.5833333333333334\n",
      "Recall\n",
      "0.37142857142857144\n",
      "F1_score\n",
      "0.4791666666666667\n",
      "[[3 5 5 5 5 5 5 3 3 5 3 5]]\n",
      "[[5 5 5 2 3 5 4 5 5 2 5 2]]\n",
      "=========================================\n",
      "precision\n",
      "0.09375\n",
      "Accuracy\n",
      "0.25\n",
      "Recall\n",
      "0.10714285714285714\n",
      "F1_score\n",
      "0.2333333333333333\n",
      "validation accuracy: 0.3888888888888889\n",
      "epoch: 21\n",
      "Epoch [22/20], Step 5, Loss: 1.4053\n",
      "precision\n",
      "0.2333333333333333\n",
      "Accuracy\n",
      "0.72\n",
      "Recall\n",
      "0.32051282051282054\n",
      "F1_score\n",
      "0.6157575757575758\n",
      "====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/20], Step 10, Loss: 1.4287\n",
      "precision\n",
      "0.2916943521594685\n",
      "Accuracy\n",
      "0.74\n",
      "Recall\n",
      "0.34285714285714286\n",
      "F1_score\n",
      "0.6461333333333333\n",
      "====================================\n",
      "epoch: 22\n",
      "Epoch [23/20], Step 5, Loss: 1.4323\n",
      "precision\n",
      "0.22525252525252526\n",
      "Accuracy\n",
      "0.7\n",
      "Recall\n",
      "0.3088624338624339\n",
      "F1_score\n",
      "0.6157377049180328\n",
      "====================================\n",
      "Epoch [23/20], Step 10, Loss: 1.4191\n",
      "precision\n",
      "0.23214285714285712\n",
      "Accuracy\n",
      "0.72\n",
      "Recall\n",
      "0.31666666666666665\n",
      "F1_score\n",
      "0.6128571428571429\n",
      "====================================\n",
      "epoch: 23\n",
      "Epoch [24/20], Step 5, Loss: 1.4345\n",
      "precision\n",
      "0.2191142191142191\n",
      "Accuracy\n",
      "0.72\n",
      "Recall\n",
      "0.3333333333333333\n",
      "F1_score\n",
      "0.6064450127877238\n",
      "====================================\n",
      "Epoch [24/20], Step 10, Loss: 1.3778\n",
      "precision\n",
      "0.30421146953405015\n",
      "Accuracy\n",
      "0.72\n",
      "Recall\n",
      "0.34490740740740744\n",
      "F1_score\n",
      "0.6371688311688312\n",
      "====================================\n",
      "epoch: 24\n",
      "Epoch [25/20], Step 5, Loss: 1.5013\n",
      "precision\n",
      "0.2560656189688448\n",
      "Accuracy\n",
      "0.62\n",
      "Recall\n",
      "0.35909090909090907\n",
      "F1_score\n",
      "0.5141337907375643\n",
      "====================================\n",
      "Epoch [25/20], Step 10, Loss: 1.5790\n",
      "precision\n",
      "0.24444444444444444\n",
      "Accuracy\n",
      "0.54\n",
      "Recall\n",
      "0.30277777777777776\n",
      "F1_score\n",
      "0.5161904761904762\n",
      "====================================\n",
      "epoch: 25\n",
      "Epoch [26/20], Step 5, Loss: 1.3723\n",
      "precision\n",
      "0.2420343137254902\n",
      "Accuracy\n",
      "0.74\n",
      "Recall\n",
      "0.30753968253968256\n",
      "F1_score\n",
      "0.6582488479262674\n",
      "====================================\n",
      "Epoch [26/20], Step 10, Loss: 1.3371\n",
      "precision\n",
      "0.3017543859649122\n",
      "Accuracy\n",
      "0.8\n",
      "Recall\n",
      "0.4\n",
      "F1_score\n",
      "0.7131428571428572\n",
      "====================================\n",
      "epoch: 26\n",
      "Epoch [27/20], Step 5, Loss: 1.3693\n",
      "precision\n",
      "0.25433125433125436\n",
      "Accuracy\n",
      "0.76\n",
      "Recall\n",
      "0.3333333333333333\n",
      "F1_score\n",
      "0.6563745819397994\n",
      "====================================\n",
      "Epoch [27/20], Step 10, Loss: 1.3989\n",
      "precision\n",
      "0.3571428571428571\n",
      "Accuracy\n",
      "0.74\n",
      "Recall\n",
      "0.3485714285714286\n",
      "F1_score\n",
      "0.672921212121212\n",
      "====================================\n",
      "epoch: 27\n",
      "Epoch [28/20], Step 5, Loss: 1.3977\n",
      "precision\n",
      "0.3226495726495726\n",
      "Accuracy\n",
      "0.74\n",
      "Recall\n",
      "0.35573476702508966\n",
      "F1_score\n",
      "0.6574285714285715\n",
      "====================================\n",
      "Epoch [28/20], Step 10, Loss: 1.4186\n",
      "precision\n",
      "0.24283559577677225\n",
      "Accuracy\n",
      "0.7\n",
      "Recall\n",
      "0.3160919540229885\n",
      "F1_score\n",
      "0.626002886002886\n",
      "====================================\n",
      "epoch: 28\n",
      "Epoch [29/20], Step 5, Loss: 1.3524\n",
      "precision\n",
      "0.35454545454545455\n",
      "Accuracy\n",
      "0.8\n",
      "Recall\n",
      "0.37142857142857144\n",
      "F1_score\n",
      "0.722051282051282\n",
      "====================================\n",
      "Epoch [29/20], Step 10, Loss: 1.4052\n",
      "precision\n",
      "0.24361259655377301\n",
      "Accuracy\n",
      "0.72\n",
      "Recall\n",
      "0.3111111111111111\n",
      "F1_score\n",
      "0.6216071428571429\n",
      "====================================\n",
      "epoch: 29\n",
      "Epoch [30/20], Step 5, Loss: 1.4968\n",
      "precision\n",
      "0.28821699134199136\n",
      "Accuracy\n",
      "0.64\n",
      "Recall\n",
      "0.3209876543209877\n",
      "F1_score\n",
      "0.6153599121663349\n",
      "====================================\n",
      "Epoch [30/20], Step 10, Loss: 1.3713\n",
      "precision\n",
      "0.3071428571428571\n",
      "Accuracy\n",
      "0.76\n",
      "Recall\n",
      "0.4\n",
      "F1_score\n",
      "0.656457142857143\n",
      "====================================\n",
      "epoch: 30\n",
      "Epoch [31/20], Step 5, Loss: 1.3132\n",
      "precision\n",
      "0.4622222222222222\n",
      "Accuracy\n",
      "0.82\n",
      "Recall\n",
      "0.5\n",
      "F1_score\n",
      "0.7610254609306409\n",
      "====================================\n",
      "Epoch [31/20], Step 10, Loss: 1.3617\n",
      "precision\n",
      "0.3405695611577964\n",
      "Accuracy\n",
      "0.76\n",
      "Recall\n",
      "0.4059139784946237\n",
      "F1_score\n",
      "0.7119999999999999\n",
      "====================================\n",
      "[[5 5 5 5 5 5 5 5 5 5 3 5]]\n",
      "[[5 3 0 2 2 5 5 5 4 5 5 2]]\n",
      "=========================================\n",
      "precision\n",
      "0.09090909090909091\n",
      "Accuracy\n",
      "0.4166666666666667\n",
      "Recall\n",
      "0.16666666666666669\n",
      "F1_score\n",
      "0.29411764705882354\n",
      "[[5 5 5 5 5 5 5 5 5 4 5 4]]\n",
      "[[5 4 5 5 3 5 2 5 5 5 1 1]]\n",
      "=========================================\n",
      "precision\n",
      "0.12\n",
      "Accuracy\n",
      "0.5\n",
      "Recall\n",
      "0.17142857142857143\n",
      "F1_score\n",
      "0.41176470588235287\n",
      "[[4 5 5 5 5 5 5 5 4 5 5 5]]\n",
      "[[5 5 5 2 3 5 4 5 5 2 5 2]]\n",
      "=========================================\n",
      "precision\n",
      "0.125\n",
      "Accuracy\n",
      "0.4166666666666667\n",
      "Recall\n",
      "0.17857142857142858\n",
      "F1_score\n",
      "0.34313725490196073\n",
      "validation accuracy: 0.4444444444444445\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Loss and optimizer\n",
    "\n",
    "# Train the model\n",
    "\n",
    "for epoch in range(31):\n",
    "    i = 0\n",
    "    acc = 0\n",
    "    print(\"epoch:\",epoch)\n",
    "    while (train_data.has_next(\"train\")):\n",
    "        img, act, labels = train_data.next_batch(\"train\")\n",
    "        labels = torch.from_numpy(labels).to(device)\n",
    "        img = torch.from_numpy(img.reshape(-1, sequence_length, 20*4096)).to(device)\n",
    "        act = torch.from_numpy(np.squeeze(act)).to(device)\n",
    "        outputs = model(img, act)\n",
    "        outputs = F.softmax(outputs)\n",
    "#         print(outputs.shape)\n",
    "#         outputs, torch.max(labels, 1)[1]\n",
    "        \n",
    "        predict = torch.max(outputs, 1)[1]\n",
    "        target = torch.max(labels, 1)[1]\n",
    "        \n",
    "        loss = criterion(outputs, target)\n",
    "        \n",
    "        \n",
    "        correct = (predict == target).squeeze()\n",
    "#         print(predict)\n",
    "#         print(target)\n",
    "#         print(\"================\")\n",
    "#         print(correct)\n",
    "        acc += torch.nonzero(correct).size(0) / predict.shape[0]\n",
    "        \n",
    "    \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        i += 1\n",
    "        if (i+1) % 5 == 0:\n",
    "            print ('Epoch [{}/{}], Step {}, Loss: {:.4f}' \n",
    "                   .format(epoch+1, num_epochs, i+1, loss.item()))\n",
    "            print(\"precision\")\n",
    "            print(metrics.precision_score(target, predict, average='macro'))\n",
    "\n",
    "            print(\"Accuracy\")\n",
    "            print(metrics.accuracy_score(target, predict))\n",
    "\n",
    "            print(\"Recall\")\n",
    "            print(metrics.recall_score(target, predict, average='macro'))\n",
    "\n",
    "            print(\"F1_score\")\n",
    "            print(metrics.f1_score(target, predict, average='weighted'))\n",
    "            \n",
    "#             print ('train accuracy:',acc/i)\n",
    "            print(\"====================================\")\n",
    "    if (epoch % 10 == 0):\n",
    "        evaluation(model)\n",
    "        path = \"/media/user/Hard_Disk/Dataset/child_accident_2/model/pytorch - 09/model-\"+str(epoch)+\".ckpt\"\n",
    "        torch.save(model, path)\n",
    "    train_data.reset_batch(\"train\")\n",
    "# # Test the model\n",
    "# with torch.no_grad():\n",
    "#     correct = 0\n",
    "#     total = 0\n",
    "#     for images, labels in test_loader:\n",
    "#         images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "#         labels = labels.to(device)\n",
    "#         outputs = model(images)\n",
    "#         _, predicted = torch.max(outputs.data, 1)\n",
    "#         total += labels.size(0)\n",
    "#         correct += (predicted == labels).sum().item()\n",
    "\n",
    "#     print('Test Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total)) \n",
    "\n",
    "# # Save the model checkpoint\n",
    "# torch.save(model.state_dict(), 'model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
