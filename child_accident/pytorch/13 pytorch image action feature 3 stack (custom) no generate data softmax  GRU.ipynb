{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class data():\n",
    "    def __init__(self, seq_length, batch_size):\n",
    "        np.random.seed(100)\n",
    "        self.seq_length = seq_length\n",
    "        self.acc_num = 334\n",
    "        self.no_acc_num = 392\n",
    "        self.split = 0.95\n",
    "        self.train_index = 0 \n",
    "        self.train_batch_size = batch_size\n",
    "        self.valid_index = 0\n",
    "        self.valid_batch_size = 10\n",
    "        self.train_next_round = True\n",
    "        self.train_end = False\n",
    "        self.valid_next_round = True\n",
    "        self.valid_end = False\n",
    "        self.read_annotation()\n",
    "        self.shuffle_data()\n",
    "        \n",
    "    def shuffle_data(self):\n",
    "        remove_file = np.array([277, 278])\n",
    "        #img_range = np.arange(0,300-self.seq_length-60,60)\n",
    "        acc_list = np.arange(1,self.acc_num+1)\n",
    "        acc_list = np.delete(acc_list, remove_file-1)\n",
    "\n",
    "        no_acc_list = np.arange(1,self.no_acc_num+1)\n",
    "        list1 = np.array(np.meshgrid(1,acc_list)).T.reshape(-1,2)\n",
    "        list2 = np.array(np.meshgrid(0,no_acc_list)).T.reshape(-1,2)\n",
    "        shuffle_list = np.concatenate([list1, list2], axis=0)\n",
    "        np.random.shuffle(shuffle_list)\n",
    "        self.train = shuffle_list[:int(shuffle_list.shape[0]*self.split)]\n",
    "        self.valid = shuffle_list[int(shuffle_list.shape[0]*self.split):] \n",
    "        \n",
    "    def read_annotation(self):\n",
    "        annotation_file = '/media/user/Hard_Disk/Dataset/child_accident_2/annotation/accident_frame.txt'\n",
    "        w = open(annotation_file, \"r\")\n",
    "        ann = w.read()\n",
    "        annotation_data = []\n",
    "        for i in ann.split(\"\\n\"):\n",
    "            b = i.split(\" \")\n",
    "            if (len(b) > 1):\n",
    "                annotation_data.append(b[1])\n",
    "        self.annotation = np.array(annotation_data).astype(\"int32\")\n",
    "        \n",
    "    def read_data(self, is_accident, dir_index):\n",
    "        data = []\n",
    "        label = []\n",
    "        img_path = '/media/user/Hard_Disk/Dataset/child_accident_2/image feature/' \n",
    "        act_path = '/media/user/Hard_Disk/Dataset/child_accident_2/action feature/' \n",
    "        if (is_accident):\n",
    "            acc_dir = \"accident/\"\n",
    "            range_start = self.annotation[dir_index-1] - self.seq_length - 0\n",
    "            range_end = self.annotation[dir_index-1] - 0\n",
    "            label.append([0,1])\n",
    "            \n",
    "        else:\n",
    "            acc_dir = \"no_accident/\"\n",
    "            range_start = 0\n",
    "            range_end = self.seq_length\n",
    "            label.append([1,0])\n",
    "            \n",
    "        dir_name = \"%04d\"%dir_index\n",
    "        img_npy = []\n",
    "        act_npy = []\n",
    "        for j in range(range_start, range_end):\n",
    "            img_feature = np.load(img_path + acc_dir + dir_name + \"/\" + str(j) + \".npy\")\n",
    "            img_npy.append(img_feature)\n",
    "            act_feature = np.load(act_path + acc_dir + dir_name + \"/\" + str(j) + \".npy\")\n",
    "            act_npy.append(act_feature)\n",
    "        \n",
    "            \n",
    "        return np.array(img_npy), np.array(act_npy) ,np.array(label)\n",
    "        \n",
    "    def next_batch(self, mode=\"train\"):\n",
    "        batch_img = []\n",
    "        batch_act = []\n",
    "        batch_y = []\n",
    "        \n",
    "        if (mode == \"valid\"):\n",
    "            if (self.valid_next_round == False):\n",
    "                end = (self.valid.shape[0] % self.valid_batch_size)\n",
    "                self.valid_end = True\n",
    "            else:\n",
    "                end = self.valid_batch_size\n",
    "        elif (mode == \"train\"):\n",
    "            if (self.train_next_round == False):\n",
    "                end = (self.train.shape[0] % self.train_batch_size)\n",
    "                self.train_end = True\n",
    "            else:\n",
    "                end = self.train_batch_size\n",
    "        for i in range(end):\n",
    "            if (mode == \"train\"):\n",
    "                img, act, label = self.read_data(self.train[self.train_index+i][0], self.train[self.train_index+i][1])\n",
    "            elif (mode == \"valid\"):\n",
    "                img, act, label = self.read_data(self.valid[self.valid_index+i][0], self.valid[self.valid_index+i][1])\n",
    "            batch_img.append(img)\n",
    "            batch_act.append(act)\n",
    "            batch_y.append(label)\n",
    "        if (mode == \"valid\"):\n",
    "            self.valid_index += self.valid_batch_size\n",
    "        elif (mode == \"train\"):\n",
    "            self.train_index += self.train_batch_size\n",
    "        \n",
    "        return np.array(batch_img), np.array(batch_act), np.squeeze(np.array(batch_y))\n",
    "    \n",
    "    def has_next(self, mode=\"train\"):\n",
    "        if (mode == \"train\"):\n",
    "            if (self.train_end):\n",
    "                return False\n",
    "            if (self.train_index + self.train_batch_size >= self.train.shape[0]-1):\n",
    "                self.train_next_round = False\n",
    "        elif (mode == \"valid\"):\n",
    "            if (self.valid_end):\n",
    "                return False\n",
    "            if (self.valid_index + self.valid_batch_size >= self.valid.shape[0]-1):\n",
    "                self.valid_next_round = False\n",
    "        return True\n",
    "    def display_shape(self):\n",
    "        print(\"train shape:\",self.train.shape, \" valid shape:\",self.valid.shape)\n",
    "        \n",
    "    def reset_batch(self, mode=\"train\"):\n",
    "        if (mode == \"train\"):\n",
    "            self.train_index = 0\n",
    "            self.train_next_round = True\n",
    "            self.train_end = False\n",
    "            np.random.shuffle(self.train)\n",
    "        elif (mode == \"valid\"):\n",
    "            self.valid_index = 0\n",
    "            self.valid_next_round = True\n",
    "            self.valid_end = False\n",
    "        \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recurrent neural network (many-to-one)\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, img_input_size, act_input_size, hidden_size, embedding_size, embedding_size2, num_layers, num_classes):\n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.img = nn.Sequential(\n",
    "            nn.Linear(img_input_size, embedding_size),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(embedding_size, embedding_size2)\n",
    "        )\n",
    "        self.act = nn.Sequential(\n",
    "            nn.Linear(act_input_size, embedding_size),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(embedding_size, embedding_size2)\n",
    "        )\n",
    "            \n",
    "        \n",
    "        self.img_fc1 = nn.Linear(img_input_size, embedding_size)\n",
    "        self.act_fc1 = nn.Linear(act_input_size, embedding_size)\n",
    "        self.img_fc2 = nn.Linear(embedding_size, embedding_size2)\n",
    "        self.act_fc2 = nn.Linear(embedding_size, embedding_size2)\n",
    "        self.lstm1 = nn.GRU(embedding_size2*2, hidden_size, num_layers,dropout=0.25, batch_first=True)\n",
    "        self.lstm2 = nn.GRU(embedding_size2*2, hidden_size, num_layers,dropout=0.25, batch_first=True)\n",
    "        self.lstm3 = nn.GRU(embedding_size2*2, hidden_size, num_layers,dropout=0.25, batch_first=True)\n",
    "        self.st3_state_h = nn.Linear(hidden_size*3, hidden_size)\n",
    "        #self.st3_state_c = nn.Linear(hidden_size*3, hidden_size)\n",
    "        self.st2_state_h = nn.Linear(hidden_size*2, hidden_size)\n",
    "        #self.st2_state_c = nn.Linear(hidden_size*2, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "    \n",
    "    def forward(self, x, y):\n",
    "        # Set initial hidden and cell states \n",
    "        x1 = self.img_fc1(x)\n",
    "        x1 = self.img_fc2(x1)\n",
    "        x2 = self.act_fc1(y)\n",
    "        x2 = self.act_fc2(x2)\n",
    "#         x1 = self.img(x)\n",
    "#         x = self.act(y)\n",
    "        x = torch.cat((x1, x2), 2)\n",
    "#         print(x.shape)\n",
    "        \n",
    "        st1_h = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
    "        #st1_c = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        \n",
    "        st2_h = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
    "        #st2_c = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        \n",
    "        st3_h = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
    "        #st3_c = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        \n",
    "        \n",
    "        for i in range(x.size(1)):\n",
    "        # Forward propagate LSTM\n",
    "            stack1_out, st1_h = self.lstm1(x[:,i].unsqueeze(1), st1_h)  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "            stack2_out, st2_h = self.lstm2(x[:,int(i/10)].unsqueeze(1), st2_h)\n",
    "            stack3_out, st3_h = self.lstm3(x[:,int(i/20)].unsqueeze(1), st3_h)\n",
    "           \n",
    "            \n",
    "            st3_h = torch.cat((st1_h, st2_h, st3_h), 2)\n",
    "            st3_h = self.st3_state_h(st3_h)\n",
    "            \n",
    "            #st3_c = torch.cat((st1_c, st2_c, st3_c), 2)\n",
    "            #st3_c = self.st3_state_c(st3_c)\n",
    "            \n",
    "            \n",
    "            st2_h = torch.cat((st1_h, st2_h), 2)\n",
    "            st2_h = self.st2_state_h(st2_h)\n",
    "            \n",
    "            #st2_c = torch.cat((st1_c, st2_c), 2)\n",
    "            #st2_c = self.st2_state_c(st2_c)\n",
    "            \n",
    "            \n",
    "        \n",
    "        # Decode the hidden state of the last time step\n",
    "        \n",
    "        out = self.fc2(stack3_out[:,-1,:])\n",
    "        \n",
    "#         out = self.fc2(out[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.5/site-packages/torch/nn/modules/rnn.py:38: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.25 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    }
   ],
   "source": [
    "model = RNN(img_input_size=20*4096, act_input_size=1024, hidden_size=1024, embedding_size=1024, embedding_size2=512, num_layers=1, num_classes=2).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.from_numpy(np.array([1,1])).type(torch.FloatTensor).to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight=w)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (687, 2)  valid shape: (37, 2)\n"
     ]
    }
   ],
   "source": [
    "sequence_length = 100\n",
    "num_epochs = 20\n",
    "train_data = data(seq_length=sequence_length, batch_size=50)\n",
    "train_data.display_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out of memory\n",
    "def test():\n",
    "    model = torch.load('pytorch - 06/model-90.ckpt')\n",
    "    while(train_data.has_next(\"valid\")):\n",
    "        img, act, labels = train_data.next_batch(\"valid\")\n",
    "        labels = torch.from_numpy(labels).to(device)\n",
    "        img = torch.from_numpy(img.reshape(-1, sequence_length, 20*4096)).to(device)\n",
    "        act = torch.from_numpy(np.squeeze(act)).to(device)\n",
    "        outputs = model(img, act)\n",
    "        outputs = F.softmax(outputs)\n",
    "        predict = torch.max(outputs, 1)[1]\n",
    "        target = torch.max(labels, 1)[1]\n",
    "        recall(predict, target)\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric(pred, y):\n",
    "    pred = np.reshape(np.array(pred.cpu().numpy()), (-1,1))\n",
    "    y = np.reshape(np.array(y.cpu().numpy()), (-1, 1))\n",
    "    print(pred.reshape(1,-1))\n",
    "    print(y.reshape(1,-1))\n",
    "    print(\"=========================================\")\n",
    "    print(\"precision\")\n",
    "    print(metrics.precision_score(y, pred, average='macro'))\n",
    "    \n",
    "    print(\"Accuracy\")\n",
    "    print(metrics.accuracy_score(y, pred))\n",
    "    \n",
    "    print(\"Recall\")\n",
    "    print(metrics.recall_score(y, pred, average='macro'))\n",
    "    \n",
    "    print(\"F1_score\")\n",
    "    print(metrics.f1_score(y, pred, average='weighted'))\n",
    "    \n",
    "    print(\"roc_auc_score\")\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y, pred)\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.plot(fpr, tpr, 'b',\n",
    "    label='AUC = %0.2f'% roc_auc)\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.plot([0,1],[0,1],'r--')\n",
    "    plt.xlim([0,1.0])\n",
    "    plt.ylim([0,1.0])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(model):\n",
    "    with torch.no_grad():\n",
    "#         i = 0\n",
    "        acc = 0\n",
    "        corr = 0\n",
    "        size = 0\n",
    "        while(train_data.has_next(\"valid\")):\n",
    "            img, act, labels = train_data.next_batch(\"valid\")\n",
    "            labels = torch.from_numpy(labels).to(device)\n",
    "            img = torch.from_numpy(img.reshape(-1, sequence_length, 20*4096)).to(device)\n",
    "            act = torch.from_numpy(np.squeeze(act)).to(device)\n",
    "#             print(\"-------------------\")\n",
    "#             print(img.shape)\n",
    "#             print(act.shape)\n",
    "            outputs = model(img, act)\n",
    "            outputs = F.softmax(outputs)\n",
    "            predict = torch.max(outputs, 1)[1]\n",
    "            target = torch.max(labels, 1)[1]\n",
    "            loss = criterion(outputs, target)\n",
    "            correct = (predict == target).squeeze()\n",
    "            corr += torch.nonzero(correct).size(0)\n",
    "            size += predict.shape[0]\n",
    "#             acc += torch.nonzero(correct).size(0) / predict.shape[0]\n",
    "#             i += 1\n",
    "#             metric(predict, target)\n",
    "        train_data.reset_batch(\"valid\")\n",
    "        print(\"validation accuracy:\",corr/size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:19: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/101], Loss: 0.8417\n",
      "train accuracy: 0.5269286754002911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:16: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy: 0.5405405405405406\n",
      "====================================\n",
      "epoch: 2\n",
      "Epoch [2/101], Loss: 0.5939\n",
      "train accuracy: 0.6171761280931587\n",
      "validation accuracy: 0.6486486486486487\n",
      "====================================\n",
      "epoch: 3\n",
      "Epoch [3/101], Loss: 0.5633\n",
      "train accuracy: 0.7234352256186317\n",
      "validation accuracy: 0.6756756756756757\n",
      "====================================\n",
      "epoch: 4\n",
      "Epoch [4/101], Loss: 0.5991\n",
      "train accuracy: 0.7510917030567685\n",
      "validation accuracy: 0.7027027027027027\n",
      "====================================\n",
      "epoch: 5\n",
      "Epoch [5/101], Loss: 0.4873\n",
      "train accuracy: 0.7685589519650655\n",
      "validation accuracy: 0.7027027027027027\n",
      "====================================\n",
      "epoch: 6\n",
      "Epoch [6/101], Loss: 0.4439\n",
      "train accuracy: 0.8296943231441049\n",
      "validation accuracy: 0.7567567567567568\n",
      "====================================\n",
      "epoch: 7\n",
      "Epoch [7/101], Loss: 0.4482\n",
      "train accuracy: 0.8733624454148472\n",
      "validation accuracy: 0.7297297297297297\n",
      "====================================\n",
      "epoch: 8\n",
      "Epoch [8/101], Loss: 0.4804\n",
      "train accuracy: 0.8544395924308588\n",
      "validation accuracy: 0.7027027027027027\n",
      "====================================\n",
      "epoch: 9\n",
      "Epoch [9/101], Loss: 0.3892\n",
      "train accuracy: 0.9024745269286754\n",
      "validation accuracy: 0.7297297297297297\n",
      "====================================\n",
      "epoch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.5/site-packages/torch/serialization.py:193: UserWarning: Couldn't retrieve source code for container of type RNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/101], Loss: 0.4296\n",
      "train accuracy: 0.9344978165938864\n",
      "validation accuracy: 0.7297297297297297\n",
      "====================================\n",
      "epoch: 11\n",
      "Epoch [11/101], Loss: 0.3219\n",
      "train accuracy: 0.9606986899563319\n",
      "validation accuracy: 0.7297297297297297\n",
      "====================================\n",
      "epoch: 12\n",
      "Epoch [12/101], Loss: 0.3746\n",
      "train accuracy: 0.9665211062590975\n",
      "validation accuracy: 0.7837837837837838\n",
      "====================================\n",
      "epoch: 13\n",
      "Epoch [13/101], Loss: 0.3161\n",
      "train accuracy: 0.9708879184861717\n",
      "validation accuracy: 0.6486486486486487\n",
      "====================================\n",
      "epoch: 14\n",
      "Epoch [14/101], Loss: 0.5299\n",
      "train accuracy: 0.9519650655021834\n",
      "validation accuracy: 0.7027027027027027\n",
      "====================================\n",
      "epoch: 15\n",
      "Epoch [15/101], Loss: 0.4872\n",
      "train accuracy: 0.7438136826783115\n",
      "validation accuracy: 0.6756756756756757\n",
      "====================================\n",
      "epoch: 16\n",
      "Epoch [16/101], Loss: 0.4169\n",
      "train accuracy: 0.9068413391557496\n",
      "validation accuracy: 0.7027027027027027\n",
      "====================================\n",
      "epoch: 17\n",
      "Epoch [17/101], Loss: 0.3765\n",
      "train accuracy: 0.9461426491994177\n",
      "validation accuracy: 0.6756756756756757\n",
      "====================================\n",
      "epoch: 18\n",
      "Epoch [18/101], Loss: 0.3155\n",
      "train accuracy: 0.9606986899563319\n",
      "validation accuracy: 0.7027027027027027\n",
      "====================================\n",
      "epoch: 19\n",
      "Epoch [19/101], Loss: 0.3233\n",
      "train accuracy: 0.9737991266375546\n",
      "validation accuracy: 0.7027027027027027\n",
      "====================================\n",
      "epoch: 20\n",
      "Epoch [20/101], Loss: 0.3411\n",
      "train accuracy: 0.9665211062590975\n",
      "validation accuracy: 0.7567567567567568\n",
      "====================================\n",
      "epoch: 21\n",
      "Epoch [21/101], Loss: 0.3417\n",
      "train accuracy: 0.9679767103347889\n",
      "validation accuracy: 0.7297297297297297\n",
      "====================================\n",
      "epoch: 22\n",
      "Epoch [22/101], Loss: 0.3419\n",
      "train accuracy: 0.9636098981077147\n",
      "validation accuracy: 0.7027027027027027\n",
      "====================================\n",
      "epoch: 23\n",
      "Epoch [23/101], Loss: 0.3694\n",
      "train accuracy: 0.9694323144104804\n",
      "validation accuracy: 0.7027027027027027\n",
      "====================================\n",
      "epoch: 24\n",
      "Epoch [24/101], Loss: 0.3403\n",
      "train accuracy: 0.9737991266375546\n",
      "validation accuracy: 0.7297297297297297\n",
      "====================================\n",
      "epoch: 25\n",
      "Epoch [25/101], Loss: 0.3430\n",
      "train accuracy: 0.9636098981077147\n",
      "validation accuracy: 0.6756756756756757\n",
      "====================================\n",
      "epoch: 26\n",
      "Epoch [26/101], Loss: 0.3806\n",
      "train accuracy: 0.9534206695778749\n",
      "validation accuracy: 0.6756756756756757\n",
      "====================================\n",
      "epoch: 27\n",
      "Epoch [27/101], Loss: 0.3944\n",
      "train accuracy: 0.9636098981077147\n",
      "validation accuracy: 0.7027027027027027\n",
      "====================================\n",
      "epoch: 28\n",
      "Epoch [28/101], Loss: 0.3406\n",
      "train accuracy: 0.9767103347889374\n",
      "validation accuracy: 0.6756756756756757\n",
      "====================================\n",
      "epoch: 29\n",
      "Epoch [29/101], Loss: 0.3136\n",
      "train accuracy: 0.9781659388646288\n",
      "validation accuracy: 0.7567567567567568\n",
      "====================================\n",
      "epoch: 30\n",
      "Epoch [30/101], Loss: 0.3421\n",
      "train accuracy: 0.9767103347889374\n",
      "validation accuracy: 0.7297297297297297\n",
      "====================================\n",
      "epoch: 31\n",
      "Epoch [31/101], Loss: 0.3403\n",
      "train accuracy: 0.9781659388646288\n",
      "validation accuracy: 0.7027027027027027\n",
      "====================================\n",
      "epoch: 32\n",
      "Epoch [32/101], Loss: 0.3133\n",
      "train accuracy: 0.9796215429403202\n",
      "validation accuracy: 0.7297297297297297\n",
      "====================================\n",
      "epoch: 33\n",
      "Epoch [33/101], Loss: 0.3943\n",
      "train accuracy: 0.9796215429403202\n",
      "validation accuracy: 0.7027027027027027\n",
      "====================================\n",
      "epoch: 34\n",
      "Epoch [34/101], Loss: 0.3133\n",
      "train accuracy: 0.9796215429403202\n",
      "validation accuracy: 0.6756756756756757\n",
      "====================================\n",
      "epoch: 35\n",
      "Epoch [35/101], Loss: 0.3133\n",
      "train accuracy: 0.9796215429403202\n",
      "validation accuracy: 0.6756756756756757\n",
      "====================================\n",
      "epoch: 36\n",
      "Epoch [36/101], Loss: 0.3403\n",
      "train accuracy: 0.9796215429403202\n",
      "validation accuracy: 0.7027027027027027\n",
      "====================================\n",
      "epoch: 37\n",
      "Epoch [37/101], Loss: 0.3133\n",
      "train accuracy: 0.9796215429403202\n",
      "validation accuracy: 0.7027027027027027\n",
      "====================================\n",
      "epoch: 38\n",
      "Epoch [38/101], Loss: 0.3673\n",
      "train accuracy: 0.9796215429403202\n",
      "validation accuracy: 0.7027027027027027\n",
      "====================================\n",
      "epoch: 39\n",
      "Epoch [39/101], Loss: 0.3405\n",
      "train accuracy: 0.9796215429403202\n",
      "validation accuracy: 0.7297297297297297\n",
      "====================================\n",
      "epoch: 40\n",
      "Epoch [40/101], Loss: 0.3433\n",
      "train accuracy: 0.9796215429403202\n",
      "validation accuracy: 0.6756756756756757\n",
      "====================================\n",
      "epoch: 41\n",
      "Epoch [41/101], Loss: 0.3405\n",
      "train accuracy: 0.9796215429403202\n",
      "validation accuracy: 0.7567567567567568\n",
      "====================================\n",
      "epoch: 42\n",
      "Epoch [42/101], Loss: 0.3944\n",
      "train accuracy: 0.9810771470160117\n",
      "validation accuracy: 0.7027027027027027\n",
      "====================================\n",
      "epoch: 43\n",
      "Epoch [43/101], Loss: 0.3133\n",
      "train accuracy: 0.9810771470160117\n",
      "validation accuracy: 0.7027027027027027\n",
      "====================================\n",
      "epoch: 44\n",
      "Epoch [44/101], Loss: 0.3403\n",
      "train accuracy: 0.9810771470160117\n",
      "validation accuracy: 0.6756756756756757\n",
      "====================================\n",
      "epoch: 45\n",
      "Epoch [45/101], Loss: 0.3403\n",
      "train accuracy: 0.9810771470160117\n",
      "validation accuracy: 0.6756756756756757\n",
      "====================================\n",
      "epoch: 46\n",
      "Epoch [46/101], Loss: 0.3133\n",
      "train accuracy: 0.9810771470160117\n",
      "validation accuracy: 0.6756756756756757\n",
      "====================================\n",
      "epoch: 47\n",
      "Epoch [47/101], Loss: 0.3133\n",
      "train accuracy: 0.9810771470160117\n",
      "validation accuracy: 0.6756756756756757\n",
      "====================================\n",
      "epoch: 48\n",
      "Epoch [48/101], Loss: 0.3133\n",
      "train accuracy: 0.9810771470160117\n",
      "validation accuracy: 0.6756756756756757\n",
      "====================================\n",
      "epoch: 49\n",
      "Epoch [49/101], Loss: 0.3133\n",
      "train accuracy: 0.9810771470160117\n",
      "validation accuracy: 0.6756756756756757\n",
      "====================================\n",
      "epoch: 50\n",
      "Epoch [50/101], Loss: 0.3133\n",
      "train accuracy: 0.9810771470160117\n",
      "validation accuracy: 0.6756756756756757\n",
      "====================================\n",
      "epoch: 51\n",
      "Epoch [51/101], Loss: 0.3133\n",
      "train accuracy: 0.9810771470160117\n",
      "validation accuracy: 0.6756756756756757\n",
      "====================================\n",
      "epoch: 52\n",
      "Epoch [52/101], Loss: 0.3403\n",
      "train accuracy: 0.9810771470160117\n",
      "validation accuracy: 0.6756756756756757\n",
      "====================================\n",
      "epoch: 53\n",
      "Epoch [53/101], Loss: 0.3403\n",
      "train accuracy: 0.9810771470160117\n",
      "validation accuracy: 0.6756756756756757\n",
      "====================================\n",
      "epoch: 54\n",
      "Epoch [54/101], Loss: 0.3403\n",
      "train accuracy: 0.9810771470160117\n",
      "validation accuracy: 0.6756756756756757\n",
      "====================================\n",
      "epoch: 55\n",
      "Epoch [55/101], Loss: 0.3403\n",
      "train accuracy: 0.9810771470160117\n",
      "validation accuracy: 0.6756756756756757\n",
      "====================================\n",
      "epoch: 56\n",
      "Epoch [56/101], Loss: 0.3133\n",
      "train accuracy: 0.9810771470160117\n",
      "validation accuracy: 0.6756756756756757\n",
      "====================================\n",
      "epoch: 57\n",
      "Epoch [57/101], Loss: 0.3133\n",
      "train accuracy: 0.9810771470160117\n",
      "validation accuracy: 0.6756756756756757\n",
      "====================================\n",
      "epoch: 58\n",
      "Epoch [58/101], Loss: 0.3133\n",
      "train accuracy: 0.9810771470160117\n",
      "validation accuracy: 0.6756756756756757\n",
      "====================================\n",
      "epoch: 59\n",
      "Epoch [59/101], Loss: 0.3403\n",
      "train accuracy: 0.9810771470160117\n",
      "validation accuracy: 0.6756756756756757\n",
      "====================================\n",
      "epoch: 60\n",
      "Epoch [60/101], Loss: 0.3133\n",
      "train accuracy: 0.9810771470160117\n",
      "validation accuracy: 0.6756756756756757\n",
      "====================================\n",
      "epoch: 61\n",
      "Epoch [61/101], Loss: 0.3403\n",
      "train accuracy: 0.9810771470160117\n",
      "validation accuracy: 0.6756756756756757\n",
      "====================================\n",
      "epoch: 62\n",
      "Epoch [62/101], Loss: 0.3133\n",
      "train accuracy: 0.9810771470160117\n",
      "validation accuracy: 0.6756756756756757\n",
      "====================================\n",
      "epoch: 63\n",
      "Epoch [63/101], Loss: 0.3673\n",
      "train accuracy: 0.9810771470160117\n",
      "validation accuracy: 0.6756756756756757\n",
      "====================================\n",
      "epoch: 64\n",
      "Epoch [64/101], Loss: 0.3403\n",
      "train accuracy: 0.9810771470160117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy: 0.6756756756756757\n",
      "====================================\n",
      "epoch: 65\n",
      "Epoch [65/101], Loss: 0.3133\n",
      "train accuracy: 0.9810771470160117\n",
      "validation accuracy: 0.6756756756756757\n",
      "====================================\n",
      "epoch: 66\n",
      "Epoch [66/101], Loss: 0.3133\n",
      "train accuracy: 0.9810771470160117\n",
      "validation accuracy: 0.6756756756756757\n",
      "====================================\n",
      "epoch: 67\n",
      "Epoch [67/101], Loss: 0.3133\n",
      "train accuracy: 0.9810771470160117\n",
      "validation accuracy: 0.6756756756756757\n",
      "====================================\n",
      "epoch: 68\n",
      "Epoch [68/101], Loss: 0.3133\n",
      "train accuracy: 0.9810771470160117\n",
      "validation accuracy: 0.6756756756756757\n",
      "====================================\n",
      "epoch: 69\n",
      "Epoch [69/101], Loss: 0.3133\n",
      "train accuracy: 0.9810771470160117\n",
      "validation accuracy: 0.6756756756756757\n",
      "====================================\n",
      "epoch: 70\n",
      "Epoch [70/101], Loss: 0.3403\n",
      "train accuracy: 0.9810771470160117\n",
      "validation accuracy: 0.6756756756756757\n",
      "====================================\n",
      "epoch: 71\n",
      "Epoch [71/101], Loss: 0.3403\n",
      "train accuracy: 0.9810771470160117\n",
      "validation accuracy: 0.6756756756756757\n",
      "====================================\n",
      "epoch: 72\n",
      "Epoch [72/101], Loss: 0.3133\n",
      "train accuracy: 0.9810771470160117\n",
      "validation accuracy: 0.6756756756756757\n",
      "====================================\n",
      "epoch: 73\n",
      "Epoch [73/101], Loss: 0.3403\n",
      "train accuracy: 0.9810771470160117\n",
      "validation accuracy: 0.6756756756756757\n",
      "====================================\n",
      "epoch: 74\n",
      "Epoch [74/101], Loss: 0.3673\n",
      "train accuracy: 0.9810771470160117\n",
      "validation accuracy: 0.6756756756756757\n",
      "====================================\n",
      "epoch: 75\n",
      "Epoch [75/101], Loss: 0.3673\n",
      "train accuracy: 0.9810771470160117\n",
      "validation accuracy: 0.6756756756756757\n",
      "====================================\n",
      "epoch: 76\n",
      "Epoch [76/101], Loss: 0.3133\n",
      "train accuracy: 0.9810771470160117\n",
      "validation accuracy: 0.6756756756756757\n",
      "====================================\n",
      "epoch: 77\n",
      "Epoch [77/101], Loss: 0.3133\n",
      "train accuracy: 0.9810771470160117\n",
      "validation accuracy: 0.6756756756756757\n",
      "====================================\n",
      "epoch: 78\n",
      "Epoch [78/101], Loss: 0.3403\n",
      "train accuracy: 0.9810771470160117\n",
      "validation accuracy: 0.6756756756756757\n",
      "====================================\n",
      "epoch: 79\n",
      "Epoch [79/101], Loss: 0.3403\n",
      "train accuracy: 0.9810771470160117\n",
      "validation accuracy: 0.6756756756756757\n",
      "====================================\n",
      "epoch: 80\n",
      "Epoch [80/101], Loss: 0.3133\n",
      "train accuracy: 0.9810771470160117\n",
      "validation accuracy: 0.6756756756756757\n",
      "====================================\n",
      "epoch: 81\n",
      "Epoch [81/101], Loss: 0.3133\n",
      "train accuracy: 0.9810771470160117\n",
      "validation accuracy: 0.6756756756756757\n",
      "====================================\n",
      "epoch: 82\n",
      "Epoch [82/101], Loss: 0.3133\n",
      "train accuracy: 0.9810771470160117\n",
      "validation accuracy: 0.7297297297297297\n",
      "====================================\n",
      "epoch: 83\n",
      "Epoch [83/101], Loss: 0.3403\n",
      "train accuracy: 0.9810771470160117\n",
      "validation accuracy: 0.6756756756756757\n",
      "====================================\n",
      "epoch: 84\n",
      "Epoch [84/101], Loss: 0.3133\n",
      "train accuracy: 0.9796215429403202\n",
      "validation accuracy: 0.7297297297297297\n",
      "====================================\n",
      "epoch: 85\n",
      "Epoch [85/101], Loss: 0.3674\n",
      "train accuracy: 0.9796215429403202\n",
      "validation accuracy: 0.7567567567567568\n",
      "====================================\n",
      "epoch: 86\n",
      "Epoch [86/101], Loss: 0.3134\n",
      "train accuracy: 0.9767103347889374\n",
      "validation accuracy: 0.7837837837837838\n",
      "====================================\n",
      "epoch: 87\n",
      "Epoch [87/101], Loss: 0.3168\n",
      "train accuracy: 0.975254730713246\n",
      "validation accuracy: 0.7027027027027027\n",
      "====================================\n",
      "epoch: 88\n",
      "Epoch [88/101], Loss: 0.3479\n",
      "train accuracy: 0.9723435225618632\n",
      "validation accuracy: 0.7297297297297297\n",
      "====================================\n",
      "epoch: 89\n",
      "Epoch [89/101], Loss: 0.3440\n",
      "train accuracy: 0.982532751091703\n",
      "validation accuracy: 0.8108108108108109\n",
      "====================================\n",
      "epoch: 90\n",
      "Epoch [90/101], Loss: 0.3455\n",
      "train accuracy: 0.9781659388646288\n",
      "validation accuracy: 0.7837837837837838\n",
      "====================================\n",
      "epoch: 91\n",
      "Epoch [91/101], Loss: 0.3403\n",
      "train accuracy: 0.975254730713246\n",
      "validation accuracy: 0.8108108108108109\n",
      "====================================\n",
      "epoch: 92\n",
      "Epoch [92/101], Loss: 0.3601\n",
      "train accuracy: 0.975254730713246\n",
      "validation accuracy: 0.8108108108108109\n",
      "====================================\n",
      "epoch: 93\n",
      "Epoch [93/101], Loss: 0.3139\n",
      "train accuracy: 0.9723435225618632\n",
      "validation accuracy: 0.7567567567567568\n",
      "====================================\n",
      "epoch: 94\n",
      "Epoch [94/101], Loss: 0.3134\n",
      "train accuracy: 0.9781659388646288\n",
      "validation accuracy: 0.7567567567567568\n",
      "====================================\n",
      "epoch: 95\n",
      "Epoch [95/101], Loss: 0.3619\n",
      "train accuracy: 0.9708879184861717\n",
      "validation accuracy: 0.7837837837837838\n",
      "====================================\n",
      "epoch: 96\n",
      "Epoch [96/101], Loss: 0.3175\n",
      "train accuracy: 0.9694323144104804\n",
      "validation accuracy: 0.7297297297297297\n",
      "====================================\n",
      "epoch: 97\n",
      "Epoch [97/101], Loss: 0.3381\n",
      "train accuracy: 0.9679767103347889\n",
      "validation accuracy: 0.6756756756756757\n",
      "====================================\n",
      "epoch: 98\n",
      "Epoch [98/101], Loss: 0.3448\n",
      "train accuracy: 0.9810771470160117\n",
      "validation accuracy: 0.6486486486486487\n",
      "====================================\n",
      "epoch: 99\n",
      "Epoch [99/101], Loss: 0.3134\n",
      "train accuracy: 0.9781659388646288\n",
      "validation accuracy: 0.6756756756756757\n",
      "====================================\n",
      "epoch: 100\n",
      "Epoch [100/101], Loss: 0.3133\n",
      "train accuracy: 0.9708879184861717\n",
      "validation accuracy: 0.7567567567567568\n",
      "====================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Loss and optimizer\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 101\n",
    "for epoch in range(1,num_epochs):\n",
    "    i = 0\n",
    "    acc = 0\n",
    "    size = 0\n",
    "    \n",
    "    print(\"epoch:\",epoch)\n",
    "    while (train_data.has_next(\"train\")):\n",
    "        img, act, labels = train_data.next_batch(\"train\")\n",
    "        labels = torch.from_numpy(labels).to(device)\n",
    "        \n",
    "        img = torch.from_numpy(img.reshape(-1, sequence_length, 20*4096)).to(device)\n",
    "        act = torch.from_numpy(np.squeeze(act)).to(device)\n",
    "        outputs = model(img, act)\n",
    "        outputs = F.softmax(outputs)\n",
    "#         print(outputs.shape)\n",
    "#         outputs, torch.max(labels, 1)[1]\n",
    "        \n",
    "        predict = torch.max(outputs, 1)[1]\n",
    "        target = torch.max(labels, 1)[1]\n",
    "        loss = criterion(outputs, target)\n",
    "        \n",
    "        \n",
    "        correct = (predict == target).squeeze()\n",
    "#         print(predict)\n",
    "#         print(target)\n",
    "#         print(\"================\")\n",
    "#         print(correct)\n",
    "        acc += torch.nonzero(correct).size(0)\n",
    "        size += predict.shape[0]\n",
    "        \n",
    "    \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "                  \n",
    "    if (epoch % 10 == 0):\n",
    "        path = \"pytorch - 13/model-\"+str(epoch)+\".ckpt\"\n",
    "        torch.save(model, path)\n",
    "    \n",
    "    print ('Epoch [{}/{}], Loss: {:.4f}'.format(epoch, num_epochs, loss.item()))\n",
    "    print ('train accuracy:',acc/size)\n",
    "    evaluation(model)\n",
    "    print(\"====================================\")\n",
    "        \n",
    "    train_data.reset_batch(\"train\")\n",
    "# # Test the model\n",
    "# with torch.no_grad():\n",
    "#     correct = 0\n",
    "#     total = 0\n",
    "#     for images, labels in test_loader:\n",
    "#         images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "#         labels = labels.to(device)\n",
    "#         outputs = model(images)\n",
    "#         _, predicted = torch.max(outputs.data, 1)\n",
    "#         total += labels.size(0)\n",
    "#         correct += (predicted == labels).sum().item()\n",
    "\n",
    "#     print('Test Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total)) \n",
    "\n",
    "# # Save the model checkpoint\n",
    "# torch.save(model.state_dict(), 'model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
