{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "import cv2\n",
    "from tensorflow.contrib import rnn\n",
    "import sklearn as sk\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_image = \"/media/user/Hard_Disk/Dataset/child_accident_2/clip image/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class data():\n",
    "    def __init__(self, path, batch_size):\n",
    "        self.path = path\n",
    "        self.acc_num = 334\n",
    "        self.no_acc_num = 392\n",
    "        self.train_index = 0\n",
    "        self.valid_index = 0\n",
    "        self.seq_length = 50\n",
    "        self.split = 0.9\n",
    "        self.batch_size = batch_size\n",
    "        self.read_annotation()\n",
    "        self.shuffle_data()\n",
    "        \n",
    "        \n",
    "    def shuffle_data(self):\n",
    "        img_range = np.arange(0,300-self.seq_length-30,30)\n",
    "        acc_list = np.arange(1,self.acc_num+1)\n",
    "        no_acc_list = np.arange(1,self.no_acc_num+1)\n",
    "        list1 = np.array(np.meshgrid(1,acc_list,img_range)).T.reshape(-1,3)\n",
    "        list2 = np.array(np.meshgrid(0,no_acc_list,img_range)).T.reshape(-1,3)\n",
    "        shuffle_list = np.concatenate([list1, list2], axis=0)\n",
    "        np.random.shuffle(shuffle_list)\n",
    "        self.train = shuffle_list[:int(shuffle_list.shape[0]*self.split)]\n",
    "        self.valid = shuffle_list[int(shuffle_list.shape[0]*self.split):]\n",
    "        \n",
    "    def read_annotation(self):\n",
    "        annotation_file = '/media/user/Hard_Disk/Dataset/child_accident_2/annotation/accident_frame.txt'\n",
    "        w = open(annotation_file, \"r\")\n",
    "        ann = w.read()\n",
    "        annotation_data = []\n",
    "        for i in ann.split(\"\\n\"):\n",
    "            b = i.split(\" \")\n",
    "            if (len(b) > 1):\n",
    "                annotation_data.append(b[1])\n",
    "        self.annotation = np.array(annotation_data).astype(\"int32\")\n",
    "        \n",
    "    def read_data(self, is_accident, dir_index, image_range):\n",
    "        data = []\n",
    "        label = []\n",
    "        if (is_accident):\n",
    "            acc_dir = \"accident/\"\n",
    "        else:\n",
    "            acc_dir = \"no_accident/\"\n",
    "        dir_name = \"%04d\"%dir_index\n",
    "        for j in range(image_range, image_range+self.seq_length):\n",
    "#             print(self.path+ acc_dir + dir_name +\"/\"+ str(j)+\".jpg\")\n",
    "            img = cv2.imread(self.path+ acc_dir + dir_name +\"/\"+ str(j)+\".jpg\")\n",
    "#             print(img.shape)\n",
    "            imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            imgRGB = cv2.resize(imgRGB, (150, 150))\n",
    "            data.append(imgRGB)\n",
    "        \n",
    "        if (is_accident and ((image_range + self.seq_length + 30) > self.annotation[dir_index-1])):\n",
    "            label.append([0,1])\n",
    "        else:\n",
    "            label.append([1,0])\n",
    "        return np.array(data),np.array(label)\n",
    "    \n",
    "    def has_train_next(self):\n",
    "        if (self.train_index + self.batch_size <= self.train.shape[0]):\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def has_valid_next(self):\n",
    "        if (self.valid_index + self.batch_size <= self.valid.shape[0]):\n",
    "            return True\n",
    "        return False\n",
    "        \n",
    "    def train_reset(self):\n",
    "        np.random.shuffle(self.train)\n",
    "        self.train_index = 0\n",
    "        \n",
    "    def valid_reset(self):\n",
    "        np.random.shuffle(self.valid)\n",
    "        self.valid_index = 0\n",
    "        \n",
    "    def next_batch_train(self):     \n",
    "        batch_x = []\n",
    "        batch_y = []\n",
    "        for i in range(self.batch_size):\n",
    "            data, label = self.read_data(self.train[self.train_index+i][0], self.train[self.train_index+i][1], self.train[self.train_index+i][2])\n",
    "            batch_x.append(data)\n",
    "            batch_y.append(label)\n",
    "        self.train_index += self.batch_size\n",
    "        return np.array(batch_x), np.squeeze(np.array(batch_y))\n",
    "    \n",
    "    def get_shape(self):\n",
    "        return self.train.shape, self.valid.shape\n",
    "    \n",
    "    def next_batch_valid(self):     \n",
    "        batch_x = []\n",
    "        batch_y = []\n",
    "        for i in range(self.batch_size):\n",
    "            data, label = self.read_data(self.valid[self.valid_index+i][0], self.valid[self.valid_index+i][1], self.valid[self.valid_index+i][2])\n",
    "            batch_x.append(data)\n",
    "            batch_y.append(label)\n",
    "        self.valid_index += self.batch_size\n",
    "        return np.array(batch_x), np.squeeze(np.array(batch_y))   \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelRNN():\n",
    "    def __init__(self, img_size_h, img_size_w, hidden_num, rnn_size, max_seq_sz, num_layers, n_classes):\n",
    "        self.img_size_h = img_size_h\n",
    "        self.img_size_w = img_size_w\n",
    "        self.hidden_num = hidden_num\n",
    "        self.rnn_size = rnn_size\n",
    "        self.input_seq = tf.placeholder('float', [None, max_seq_sz, img_size_h, img_size_w, 3])\n",
    "        self.target = tf.placeholder('float', [None, n_classes])\n",
    "        self.max_seq_sz = max_seq_sz\n",
    "        self.num_layers = num_layers\n",
    "        self.n_classes = n_classes\n",
    "        self.__build()\n",
    "        \n",
    "    def __conv2d(x, W):\n",
    "        return tf.nn.conv2d(x,W, strides=[1,3,3,1], padding='SAME')\n",
    "    \n",
    "    def __max_pool_2x2(x):\n",
    "        return tf.nn.max_pool(x, ksize=[1,2,2,1],strides=[1,2,2,1], padding='SAME')\n",
    "        \n",
    "    def __weight_variable(self, shape, myName):\n",
    "        initial = tf.random_normal(shape, stddev=0.1, name=myName)\n",
    "        return tf.Variable(initial)\n",
    "    \n",
    "    \n",
    "    def __bias_variable(self, shape, myName):\n",
    "        initial = tf.constant(0.1, shape=shape, name=myName)\n",
    "        return tf.Variable(initial)\n",
    "\n",
    "    def __build(self):\n",
    "        w_fc_in = self.__weight_variable([self.img_size_h*self.img_size_w*3, self.hidden_num], 'w_fc_in')\n",
    "        b_fc_in = self.__bias_variable([self.hidden_num], 'b_fc_in')\n",
    "        \n",
    "        w_fc_o = self.__weight_variable([self.rnn_size, self.hidden_num], 'w_fc_o')\n",
    "        b_fc_o = self.__bias_variable([self.hidden_num], 'b_fc_o')\n",
    "                \n",
    "        w_output_action = self.__weight_variable([self.hidden_num, self.n_classes], 'w_fc_in')\n",
    "        b_output_action = self.__bias_variable([self.n_classes], 'b_fc_in')\n",
    "           \n",
    "        x = tf.reshape(self.input_seq, [-1, self.img_size_h*self.img_size_w*3])\n",
    "\n",
    "        h1 = tf.nn.relu(tf.matmul(x, w_fc_in) + b_fc_in)\n",
    "        h1 = tf.reshape(h1, [-1, self.max_seq_sz, self.hidden_num])\n",
    "        \n",
    "        #rnn\n",
    "        h1 = tf.unstack(h1, axis=1)\n",
    "        def get_cell():\n",
    "            return rnn.GRUCell(self.rnn_size)   \n",
    "        gru_cell = rnn.MultiRNNCell([get_cell() for _ in range(self.num_layers)])\n",
    "        outputs, states = rnn.static_rnn(gru_cell, h1, dtype=tf.float32) \n",
    "        #fc_o\n",
    "        h2 = tf.nn.relu(tf.matmul(outputs[-1], w_fc_o) + b_fc_o)\n",
    "        #output\n",
    "#         output_label = tf.nn.softmax(tf.matmul(h2, w_output_action) + b_output_action)\n",
    "        output_label = tf.matmul(h2, w_output_action) + b_output_action\n",
    "        #    \n",
    "        self.correct_prediction = tf.equal(tf.argmax(output_label,1), tf.argmax(self.target, 1))\n",
    "        \n",
    "        \n",
    "        self.prediction = output_label\n",
    "        self.saver = tf.train.Saver(write_version=tf.train.SaverDef.V2, max_to_keep=100)\n",
    "        \n",
    "    def test(self, sess, batch_gen):\n",
    "        accuracy = tf.reduce_mean(tf.cast(self.correct_prediction, tf.float32))\n",
    "        i = 0\n",
    "        tStart_epoch = time.time()\n",
    "        y_pred = []\n",
    "        y_true = []\n",
    "        epoch_acc = 0\n",
    "        while(batch_gen.has_valid_next()):\n",
    "            batch_in, batch_target = batch_gen.next_batch_valid()\n",
    "\n",
    "            pred, acc = sess.run([self.prediction, accuracy], feed_dict={self.input_seq: batch_in, self.target: batch_target})\n",
    "            epoch_acc += acc\n",
    "#                 a = sess.run([self.pred], feed_dict={self.input_seq: batch_in, self.target: batch_target} )\n",
    "            i=i+1\n",
    "            y_pred.append(np.squeeze(np.array(np.argmax(pred, 1))))\n",
    "            y_true.append(np.argmax(batch_target, 1))\n",
    "           \n",
    "        tStop_epoch = time.time()\n",
    "        batch_gen.valid_reset()\n",
    "#         self.evaluation(np.array(y_pred).reshape(-1,2), np.array(y_true).reshape(-1,2))\n",
    "#         print(\"Precision:\",epoch_prec/i, \" Recall:\", epoch_recall/i, \" F1_score:\",epoch_f1/i)\n",
    "        print(\"valid accuracy:\",epoch_acc/i)\n",
    "        \n",
    "        \n",
    "    def train(self, sess, model_save_path, batch_gen, n_epochs, save_freq):\n",
    "        accuracy = tf.reduce_mean(tf.cast(self.correct_prediction, tf.float32))\n",
    "        loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=self.target, logits=self.prediction))\n",
    "        optimizer = tf.train.AdamOptimizer(0.001).minimize(loss)\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        saver = tf.train.Saver()\n",
    "        saver.restore(sess, \"RNN_model/epoch-8/model.ckpt\")\n",
    "        for epoch in range(n_epochs):\n",
    "            epoch_loss = 0\n",
    "            epoch_acc = 0\n",
    "            i=0\n",
    "            tStart_epoch = time.time()\n",
    "            while(batch_gen.has_train_next()):\n",
    "#                 print(\"batch:\",i+1)\n",
    "                batch_in, batch_target = batch_gen.next_batch_train()\n",
    "#                 print(batch_in.shape, batch_target.shape)\n",
    "#                 print(batch_in[0])\n",
    "                _, err, acc, pred = sess.run([optimizer, loss, accuracy, self.correct_prediction], feed_dict={self.input_seq: batch_in, self.target: batch_target})\n",
    "#                 a = sess.run([self.pred], feed_dict={self.input_seq: batch_in, self.target: batch_target} )\n",
    "                i=i+1\n",
    "                epoch_loss += err   \n",
    "                epoch_acc += acc\n",
    "            \n",
    "            tStop_epoch = time.time()\n",
    "            batch_gen.train_reset()\n",
    "            print (\"Epoch Time Cost:\", round(tStop_epoch - tStart_epoch,2), \"s\")\n",
    "            print ('epoch loss:',(epoch_loss/i))\n",
    "            print ('epoch acc:',(epoch_acc/i))\n",
    "            if epoch%save_freq==0:  \n",
    "                self.test(sess, batch_gen)\n",
    "                \n",
    "                path = model_save_path+\"/epoch-\"+str(epoch+1)\n",
    "                if not os.path.exists(path):\n",
    "                    os.makedirs(path)\n",
    "                saver.save(sess, path+\"/model.ckpt\")\n",
    "    \n",
    "    def prediction(self, sess, model_save_path, batch_in):\n",
    "        saver = tf.train.Saver()\n",
    "        saver.restore(sess, model_save_path)\n",
    "        pred = sess.run([self.prediction], feed_dict={self.input_seq: batch_in})\n",
    "        return pred\n",
    "        \n",
    "    def evaluation(self, predict, ground):\n",
    "        TP = np.count_nonzero(y_pred * y_true)\n",
    "        TN = np.count_nonzero((y_pred - 1) * (y_true - 1))\n",
    "        FP = np.count_nonzero(y_pred * (y_true - 1))\n",
    "        FN = np.count_nonzero((y_pred - 1) * y_true)\n",
    "        \n",
    "        precision = TP / (TP + FP)\n",
    "        recall = TP / (TP + FN)\n",
    "        f1 = 2 * precision * recall / (precision + recall)\n",
    "        return precision, recall, f1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelRNN(img_size_h=150, img_size_w=150, hidden_num=1024, rnn_size=512, max_seq_sz= 50, num_layers=1, n_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_gen = data(clip_image, batch_size=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-4-be3a4757b4bf>:88: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from RNN_model/epoch-8/model.ckpt\n",
      "Epoch Time Cost: 922.69 s\n",
      "epoch loss: 0.37930988433987894\n",
      "epoch acc: 0.8756218863614802\n",
      "valid accuracy: 0.8506944387530287\n",
      "Epoch Time Cost: 908.86 s\n",
      "epoch loss: 0.3784918380745106\n",
      "epoch acc: 0.8756218857455883\n",
      "Epoch Time Cost: 908.14 s\n",
      "epoch loss: 0.3774412806850487\n",
      "epoch acc: 0.875813237561424\n",
      "Epoch Time Cost: 908.07 s\n",
      "epoch loss: 0.37881145716979503\n",
      "epoch acc: 0.8756218856429396\n",
      "Epoch Time Cost: 908.03 s\n",
      "epoch loss: 0.37696826662419175\n",
      "epoch acc: 0.875621885848237\n",
      "Epoch Time Cost: 908.77 s\n",
      "epoch loss: 0.37705564039548695\n",
      "epoch acc: 0.8758132365349377\n",
      "valid accuracy: 0.8489583258827528\n",
      "Epoch Time Cost: 912.69 s\n",
      "epoch loss: 0.37858845999231294\n",
      "epoch acc: 0.8756218859508856\n",
      "Epoch Time Cost: 917.5 s\n",
      "epoch loss: 0.3776778571401754\n",
      "epoch acc: 0.8756218850954802\n",
      "Epoch Time Cost: 915.48 s\n",
      "epoch loss: 0.3778477392141225\n",
      "epoch acc: 0.8756218850954802\n",
      "Epoch Time Cost: 911.63 s\n",
      "epoch loss: 0.3775674038396637\n",
      "epoch acc: 0.8758132362269917\n",
      "Epoch Time Cost: 911.47 s\n",
      "epoch loss: 0.379159601655469\n",
      "epoch acc: 0.875621886327264\n",
      "valid accuracy: 0.8489583286767205\n",
      "Epoch Time Cost: 922.19 s\n",
      "epoch loss: 0.37842941266216173\n",
      "epoch acc: 0.8756218848559667\n",
      "Epoch Time Cost: 922.43 s\n",
      "epoch loss: 0.4389875315296962\n",
      "epoch acc: 0.868924603208335\n",
      "Epoch Time Cost: 921.8 s\n",
      "epoch loss: 0.3857406004493464\n",
      "epoch acc: 0.8756218848217505\n",
      "Epoch Time Cost: 920.98 s\n",
      "epoch loss: 0.37928342762757117\n",
      "epoch acc: 0.875621886190399\n",
      "Epoch Time Cost: 921.26 s\n",
      "epoch loss: 0.3789771206839487\n",
      "epoch acc: 0.8756218854718586\n",
      "valid accuracy: 0.8472222201526165\n",
      "Epoch Time Cost: 916.67 s\n",
      "epoch loss: 0.37915486103323653\n",
      "epoch acc: 0.8756218856087234\n",
      "Epoch Time Cost: 917.62 s\n",
      "epoch loss: 0.3771983514337808\n",
      "epoch acc: 0.8758132369797484\n",
      "Epoch Time Cost: 917.87 s\n",
      "epoch loss: 0.37734615430663565\n",
      "epoch acc: 0.8756218851981289\n",
      "Epoch Time Cost: 916.99 s\n",
      "epoch loss: 0.3773642050788816\n",
      "epoch acc: 0.8756218851296965\n",
      "Epoch Time Cost: 917.81 s\n",
      "epoch loss: 0.3782497108170825\n",
      "epoch acc: 0.8756218856087234\n",
      "valid accuracy: 0.8489583302289248\n",
      "Epoch Time Cost: 919.55 s\n",
      "epoch loss: 0.37739207152486803\n",
      "epoch acc: 0.8756218857455883\n",
      "Epoch Time Cost: 920.15 s\n",
      "epoch loss: 0.3773819686487813\n",
      "epoch acc: 0.8756218855573992\n",
      "Epoch Time Cost: 919.83 s\n",
      "epoch loss: 0.37744232176468373\n",
      "epoch acc: 0.8756218856429396\n",
      "Epoch Time Cost: 924.27 s\n",
      "epoch loss: 0.37766270826214626\n",
      "epoch acc: 0.875621886977372\n",
      "Epoch Time Cost: 928.28 s\n",
      "epoch loss: 0.3774941006395217\n",
      "epoch acc: 0.875621886190399\n",
      "valid accuracy: 0.8472222159616649\n",
      "Epoch Time Cost: 947.3 s\n",
      "epoch loss: 0.3773819264601895\n",
      "epoch acc: 0.8756218855402911\n",
      "Epoch Time Cost: 946.83 s\n",
      "epoch loss: 0.3775420010551793\n",
      "epoch acc: 0.8756218854718586\n",
      "Epoch Time Cost: 946.76 s\n",
      "epoch loss: 0.3782594543459358\n",
      "epoch acc: 0.8756218854376424\n",
      "Epoch Time Cost: 946.32 s\n",
      "epoch loss: 0.37900175115715895\n",
      "epoch acc: 0.8756218861219667\n",
      "Epoch Time Cost: 946.29 s\n",
      "epoch loss: 0.37745289247051034\n",
      "epoch acc: 0.8756218857798045\n",
      "valid accuracy: 0.8489583305393656\n",
      "Epoch Time Cost: 929.81 s\n",
      "epoch loss: 0.3781783906347305\n",
      "epoch acc: 0.8756218854205343\n",
      "Epoch Time Cost: 928.85 s\n",
      "epoch loss: 0.37786602731858276\n",
      "epoch acc: 0.8756218851981289\n",
      "Epoch Time Cost: 928.43 s\n",
      "epoch loss: 0.37676196454689503\n",
      "epoch acc: 0.8756218855060748\n",
      "Epoch Time Cost: 929.1 s\n",
      "epoch loss: 0.37674232119807693\n",
      "epoch acc: 0.8756218857113721\n",
      "Epoch Time Cost: 928.9 s\n",
      "epoch loss: 0.37759910436640104\n",
      "epoch acc: 0.8756218856771559\n",
      "valid accuracy: 0.8472222207734982\n",
      "Epoch Time Cost: 932.66 s\n",
      "epoch loss: 0.3778669260587676\n",
      "epoch acc: 0.8756218856429396\n",
      "Epoch Time Cost: 932.2 s\n",
      "epoch loss: 0.3781844438679183\n",
      "epoch acc: 0.8756218858140208\n",
      "Epoch Time Cost: 932.88 s\n",
      "epoch loss: 0.3785556640163765\n",
      "epoch acc: 0.8756218858824532\n",
      "Epoch Time Cost: 932.59 s\n",
      "epoch loss: 0.37809026811002455\n",
      "epoch acc: 0.8756218858824532\n",
      "Epoch Time Cost: 932.68 s\n",
      "epoch loss: 0.37703608369923075\n",
      "epoch acc: 0.875813237390343\n",
      "valid accuracy: 0.8506944390634695\n",
      "Epoch Time Cost: 926.74 s\n",
      "epoch loss: 0.37793269259031825\n",
      "epoch acc: 0.8756218853349937\n",
      "Epoch Time Cost: 926.8 s\n",
      "epoch loss: 0.3770775545974413\n",
      "epoch acc: 0.8756218854034262\n",
      "Epoch Time Cost: 927.24 s\n",
      "epoch loss: 0.37738302983899613\n",
      "epoch acc: 0.8756218851639127\n",
      "Epoch Time Cost: 926.38 s\n",
      "epoch loss: 0.377368977026058\n",
      "epoch acc: 0.875621886019318\n",
      "Epoch Time Cost: 928.84 s\n",
      "epoch loss: 0.37844950707477487\n",
      "epoch acc: 0.8756218855231829\n",
      "valid accuracy: 0.8472222182899714\n",
      "Epoch Time Cost: 934.15 s\n",
      "epoch loss: 0.377975600655057\n",
      "epoch acc: 0.8756218858653451\n",
      "Epoch Time Cost: 934.32 s\n",
      "epoch loss: 0.3770630610112345\n",
      "epoch acc: 0.8756218854034262\n",
      "Epoch Time Cost: 934.99 s\n",
      "epoch loss: 0.37723699324987786\n",
      "epoch acc: 0.8756218860535342\n",
      "Epoch Time Cost: 933.07 s\n",
      "epoch loss: 0.377272543998865\n",
      "epoch acc: 0.8756218850270479\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    model.train(sess, model_save_path=\"RNN_model\", batch_gen=batch_gen, n_epochs=50, save_freq=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
