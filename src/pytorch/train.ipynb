{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import os\n",
    "import shutil\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "import torch.backends.cudnn as cudnn\n",
    "from read_data import TripletImageLoader\n",
    "from tripletnet import Tripletnet\n",
    "from visdom import Visdom\n",
    "import torchvision.models as models\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--name'], dest='name', nargs=None, const=None, default='TripletNet', type=<class 'str'>, choices=None, help='name of experiment', metavar=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description='PyTorch MNIST Example')\n",
    "parser.add_argument('--batch-size', type=int, default=64, metavar='N',\n",
    "                    help='input batch size for training (default: 64)')\n",
    "parser.add_argument('--test-batch-size', type=int, default=1000, metavar='N',\n",
    "                    help='input batch size for testing (default: 1000)')\n",
    "parser.add_argument('--epochs', type=int, default=10, metavar='N',\n",
    "                    help='number of epochs to train (default: 10)')\n",
    "parser.add_argument('--lr', type=float, default=0.01, metavar='LR',\n",
    "                    help='learning rate (default: 0.01)')\n",
    "parser.add_argument('--momentum', type=float, default=0.5, metavar='M',\n",
    "                    help='SGD momentum (default: 0.5)')\n",
    "parser.add_argument('--no-cuda', action='store_true', default=False,\n",
    "                    help='enables CUDA training')\n",
    "parser.add_argument('--seed', type=int, default=1, metavar='S',\n",
    "                    help='random seed (default: 1)')\n",
    "parser.add_argument('--log-interval', type=int, default=20, metavar='N',\n",
    "                    help='how many batches to wait before logging training status')\n",
    "parser.add_argument('--margin', type=float, default=0.2, metavar='M',\n",
    "                    help='margin for triplet loss (default: 0.2)')\n",
    "parser.add_argument('--resume', default='', type=str,\n",
    "                    help='path to latest checkpoint (default: none)')\n",
    "parser.add_argument('--name', default='TripletNet', type=str,\n",
    "                    help='name of experiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    global args, best_acc\n",
    "    args = parser.parse_args()\n",
    "    args.cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "    torch.manual_seed(args.seed)\n",
    "    if args.cuda:\n",
    "        torch.cuda.manual_seed(args.seed)\n",
    "    global plotter \n",
    "    plotter = VisdomLinePlotter(env_name=args.name)\n",
    "\n",
    "    kwargs = {'num_workers': 1, 'pin_memory': True} if args.cuda else {}\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        TripletImageLoader('../../dataset/train/', triplets_file_name=\"triplets_train.csv\"),\n",
    "        batch_size=args.batch_size, shuffle=True, **kwargs)\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        TripletImageLoader('../../dataset/train/', triplets_file_name=\"triplets_valid.csv\"),\n",
    "        batch_size=args.batch_size, shuffle=True, **kwargs)\n",
    "\n",
    "    model = models.resnet101(pretrained=True)\n",
    "    tnet = Tripletnet(model)\n",
    "    if args.cuda:\n",
    "        tnet.cuda()\n",
    "\n",
    "    # optionally resume from a checkpoint\n",
    "    if args.resume:\n",
    "        if os.path.isfile(args.resume):\n",
    "            print(\"=> loading checkpoint '{}'\".format(args.resume))\n",
    "            checkpoint = torch.load(args.resume)\n",
    "            args.start_epoch = checkpoint['epoch']\n",
    "            best_prec1 = checkpoint['best_prec1']\n",
    "            tnet.load_state_dict(checkpoint['state_dict'])\n",
    "            print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "                    .format(args.resume, checkpoint['epoch']))\n",
    "        else:\n",
    "            print(\"=> no checkpoint found at '{}'\".format(args.resume))\n",
    "\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "    criterion = torch.nn.MarginRankingLoss(margin = args.margin)\n",
    "    optimizer = optim.SGD(tnet.parameters(), lr=args.lr, momentum=args.momentum)\n",
    "\n",
    "    n_parameters = sum([p.data.nelement() for p in tnet.parameters()])\n",
    "    print('  + Number of params: {}'.format(n_parameters))\n",
    "\n",
    "    for epoch in range(1, args.epochs + 1):\n",
    "        # train for one epoch\n",
    "        train(train_loader, tnet, criterion, optimizer, epoch)\n",
    "        # evaluate on validation set\n",
    "        acc = test(test_loader, tnet, criterion, epoch)\n",
    "\n",
    "        # remember best acc and save checkpoint\n",
    "        is_best = acc > best_acc\n",
    "        best_acc = max(acc, best_acc)\n",
    "        save_checkpoint({\n",
    "            'epoch': epoch + 1,\n",
    "            'state_dict': tnet.state_dict(),\n",
    "            'best_prec1': best_acc,\n",
    "        }, is_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, tnet, criterion, optimizer, epoch):\n",
    "    losses = AverageMeter()\n",
    "    accs = AverageMeter()\n",
    "    emb_norms = AverageMeter()\n",
    "\n",
    "    # switch to train mode\n",
    "    tnet.train()\n",
    "    for batch_idx, (data1, data2, data3) in enumerate(train_loader):\n",
    "        if args.cuda:\n",
    "            data1, data2, data3 = data1.cuda(), data2.cuda(), data3.cuda()\n",
    "        data1, data2, data3 = Variable(data1), Variable(data2), Variable(data3)\n",
    "\n",
    "        # compute output\n",
    "        dista, distb, embedded_x, embedded_y, embedded_z = tnet(data1, data2, data3)\n",
    "        # 1 means, dista should be larger than distb\n",
    "        target = torch.FloatTensor(dista.size()).fill_(1)\n",
    "        if args.cuda:\n",
    "            target = target.cuda()\n",
    "        target = Variable(target)\n",
    "        \n",
    "        loss_triplet = criterion(dista, distb, target)\n",
    "        loss_embedd = embedded_x.norm(2) + embedded_y.norm(2) + embedded_z.norm(2)\n",
    "        loss = loss_triplet + 0.001 * loss_embedd\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        acc = accuracy(dista, distb)\n",
    "        losses.update(loss_triplet.data[0], data1.size(0))\n",
    "        accs.update(acc, data1.size(0))\n",
    "        emb_norms.update(loss_embedd.data[0]/3, data1.size(0))\n",
    "\n",
    "        # compute gradient and do optimizer step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % args.log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{}]\\t'\n",
    "                  'Loss: {:.4f} ({:.4f}) \\t'\n",
    "                  'Acc: {:.2f}% ({:.2f}%) \\t'\n",
    "                  'Emb_Norm: {:.2f} ({:.2f})'.format(\n",
    "                epoch, batch_idx * len(data1), len(train_loader.dataset),\n",
    "                losses.val, losses.avg, \n",
    "                100. * accs.val, 100. * accs.avg, emb_norms.val, emb_norms.avg))\n",
    "    # log avg values to somewhere\n",
    "    plotter.plot('acc', 'train', epoch, accs.avg)\n",
    "    plotter.plot('loss', 'train', epoch, losses.avg)\n",
    "    plotter.plot('emb_norms', 'train', epoch, emb_norms.avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(test_loader, tnet, criterion, epoch):\n",
    "    losses = AverageMeter()\n",
    "    accs = AverageMeter()\n",
    "\n",
    "    # switch to evaluation mode\n",
    "    tnet.eval()\n",
    "    for batch_idx, (data1, data2, data3) in enumerate(test_loader):\n",
    "        if args.cuda:\n",
    "            data1, data2, data3 = data1.cuda(), data2.cuda(), data3.cuda()\n",
    "        data1, data2, data3 = Variable(data1), Variable(data2), Variable(data3)\n",
    "\n",
    "        # compute output\n",
    "        dista, distb, _, _, _ = tnet(data1, data2, data3)\n",
    "        target = torch.FloatTensor(dista.size()).fill_(1)\n",
    "        if args.cuda:\n",
    "            target = target.cuda()\n",
    "        target = Variable(target)\n",
    "        test_loss =  criterion(dista, distb, target).data[0]\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        acc = accuracy(dista, distb)\n",
    "        accs.update(acc, data1.size(0))\n",
    "        losses.update(test_loss, data1.size(0))      \n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {:.2f}%\\n'.format(\n",
    "        losses.avg, 100. * accs.avg))\n",
    "    plotter.plot('acc', 'test', epoch, accs.avg)\n",
    "    plotter.plot('loss', 'test', epoch, losses.avg)\n",
    "    return accs.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
    "    \"\"\"Saves checkpoint to disk\"\"\"\n",
    "    directory = \"runs/%s/\"%(args.name)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    filename = directory + filename\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, 'runs/%s/'%(args.name) + 'model_best.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VisdomLinePlotter(object):\n",
    "    \"\"\"Plots to Visdom\"\"\"\n",
    "    def __init__(self, env_name='main'):\n",
    "        self.viz = Visdom()\n",
    "        self.env = env_name\n",
    "        self.plots = {}\n",
    "    def plot(self, var_name, split_name, x, y):\n",
    "        if var_name not in self.plots:\n",
    "            self.plots[var_name] = self.viz.line(X=np.array([x,x]), Y=np.array([y,y]), env=self.env, opts=dict(\n",
    "                legend=[split_name],\n",
    "                title=var_name,\n",
    "                xlabel='Epochs',\n",
    "                ylabel=var_name\n",
    "            ))\n",
    "        else:\n",
    "            self.viz.updateTrace(X=np.array([x]), Y=np.array([y]), env=self.env, win=self.plots[var_name], name=split_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(dista, distb):\n",
    "    margin = 0\n",
    "    pred = (dista - distb - margin).cpu().data\n",
    "    return (pred > 0).sum()*1.0/dista.size()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--batch-size N] [--test-batch-size N]\n",
      "                             [--epochs N] [--lr LR] [--momentum M] [--no-cuda]\n",
      "                             [--seed S] [--log-interval N] [--margin M]\n",
      "                             [--resume RESUME] [--name NAME]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /run/user/1000/jupyter/kernel-432203be-191d-4e0c-a915-7e6ae68f5a35.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py:2971: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
