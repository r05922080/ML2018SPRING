{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#part of the code is from https://github.com/maciejkula/triplet_recommendations_keras\n",
    "#based on code provided on Kaggle kernel\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from PIL import Image\n",
    "from keras import backend as K\n",
    "from keras import optimizers, losses, activations, models\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Embedding, Flatten, Input, merge\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, GlobalMaxPooling2D\n",
    "from keras.layers import Convolution2D, Dropout, BatchNormalization, \\\n",
    "                            GlobalMaxPool2D, Concatenate, GlobalAveragePooling2D, Lambda\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau, TensorBoard\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.preprocessing.image import random_rotation, random_shift, random_shear, random_zoom, \\\n",
    "                            random_channel_shift, transform_matrix_offset_center, img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "input_shape = (256, 256)\n",
    "base_path = \"../dataset/train/\"\n",
    "file_path = \"triplet_model_with_data_aug_weights.best.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class sample_gen(object):\n",
    "    def __init__(self, file_class_mapping, other_class = \"new_whale\"):\n",
    "        self.file_class_mapping= file_class_mapping\n",
    "        self.class_to_list_files = defaultdict(list)\n",
    "        self.list_other_class = []\n",
    "        self.list_all_files = list(file_class_mapping.keys())\n",
    "        self.range_all_files = list(range(len(self.list_all_files)))\n",
    "\n",
    "        for file, class_ in file_class_mapping.items():\n",
    "            #if class_ == other_class:\n",
    "            #    self.list_other_class.append(file)\n",
    "            #else:\n",
    "            self.class_to_list_files[class_].append(file)\n",
    "\n",
    "        self.list_classes = list(set(self.file_class_mapping.values()))\n",
    "        self.range_list_classes= range(len(self.list_classes))\n",
    "        \n",
    "        #FINAL add new_whale\n",
    "        self.class_weight = np.array([len(self.class_to_list_files[class_]) for class_ in self.list_classes])\n",
    "        self.class_weight = self.class_weight/np.sum(self.class_weight)\n",
    "\n",
    "    def get_sample(self):\n",
    "        class_idx = np.random.choice(self.range_list_classes, 1, p=self.class_weight)[0]\n",
    "        #FINAL not new whale, choose any two whales in class (could be same)\n",
    "        if self.list_classes[class_idx] != \"new_whale\":\n",
    "            examples_class_idx = np.random.choice(range(len(self.class_to_list_files[self.list_classes[class_idx]])), 2)\n",
    "            positive_example_1, positive_example_2 = \\\n",
    "                self.class_to_list_files[self.list_classes[class_idx]][examples_class_idx[0]],\\\n",
    "                self.class_to_list_files[self.list_classes[class_idx]][examples_class_idx[1]]\n",
    "        #FINAL new whale, use same sample\n",
    "        else:\n",
    "            examples_class_idx = np.random.choice(range(len(self.class_to_list_files[\"new_whale\"])), 1)\n",
    "            positive_example_1, positive_example_2 = \\\n",
    "                self.class_to_list_files[\"new_whale\"][examples_class_idx[0]],\\\n",
    "                self.class_to_list_files[\"new_whale\"][examples_class_idx[0]]\n",
    "\n",
    "        negative_example = None\n",
    "        while negative_example is None or \\\n",
    "                (self.file_class_mapping[negative_example] == self.file_class_mapping[positive_example_1] and self.file_class_mapping[positive_example_1] != \"new_whale\") or \\\n",
    "                (negative_example == positive_example_1):\n",
    "            negative_example_idx = np.random.choice(self.range_all_files, 1)[0]\n",
    "            negative_example = self.list_all_files[negative_example_idx]\n",
    "        return positive_example_1, negative_example, positive_example_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_loss(y_true, y_pred):\n",
    "\n",
    "    return K.mean(y_pred - 0 * y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bpr_triplet_loss(X):\n",
    "    positive_item_latent, negative_item_latent, user_latent = X\n",
    "    # BPR loss\n",
    "    loss = 1.0 - K.sigmoid(\n",
    "        K.sum(user_latent * positive_item_latent, axis=-1, keepdims=True) -\n",
    "        K.sum(user_latent * negative_item_latent, axis=-1, keepdims=True))\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_base_model():\n",
    "    latent_dim = 50\n",
    "    base_model = ResNet50(include_top=False, weights='imagenet') # use weights='imagenet' locally\n",
    "\n",
    "    # for layer in base_model.layers:\n",
    "    #     layer.trainable = False\n",
    "\n",
    "    x = base_model.output\n",
    "    x = GlobalMaxPooling2D()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    dense_1 = Dense(latent_dim)(x)\n",
    "    normalized = Lambda(lambda  x: K.l2_normalize(x, axis=1))(dense_1)\n",
    "    base_model = Model(base_model.input, normalized, name=\"base_model\")\n",
    "    return base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    base_model = get_base_model()\n",
    "\n",
    "    positive_example_1 = Input(input_shape+(3,) , name='positive_example_1')\n",
    "    negative_example = Input(input_shape+(3,), name='negative_example')\n",
    "    positive_example_2 = Input(input_shape+(3,), name='positive_example_2')\n",
    "\n",
    "    positive_example_1_out = base_model(positive_example_1)\n",
    "    negative_example_out = base_model(negative_example)\n",
    "    positive_example_2_out = base_model(positive_example_2)\n",
    "\n",
    "    loss = merge(\n",
    "        [positive_example_1_out, negative_example_out, positive_example_2_out],\n",
    "        mode=bpr_triplet_loss,\n",
    "        name='loss',\n",
    "        output_shape=(1, ))\n",
    "\n",
    "    model = Model(\n",
    "        input=[positive_example_1, negative_example, positive_example_2],\n",
    "        output=loss)\n",
    "    model.compile(loss=identity_loss, optimizer=Adam(0.000001))\n",
    "\n",
    "    print(model.summary())\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_inference_model(weight_path=file_path):\n",
    "    base_model = get_base_model()\n",
    "\n",
    "    positive_example_1 = Input(input_shape+(3,) , name='positive_example_1')\n",
    "    negative_example = Input(input_shape+(3,), name='negative_example')\n",
    "    positive_example_2 = Input(input_shape+(3,), name='positive_example_2')\n",
    "\n",
    "    positive_example_1_out = base_model(positive_example_1)\n",
    "    negative_example_out = base_model(negative_example)\n",
    "    positive_example_2_out = base_model(positive_example_2)\n",
    "\n",
    "    loss = merge(\n",
    "        [positive_example_1_out, negative_example_out, positive_example_2_out],\n",
    "        mode=bpr_triplet_loss,\n",
    "        name='loss',\n",
    "        output_shape=(1, ))\n",
    "\n",
    "    model = Model(\n",
    "        input=[positive_example_1, negative_example, positive_example_2],\n",
    "        output=loss)\n",
    "    model.compile(loss=identity_loss, optimizer=Adam(0.000001))\n",
    "\n",
    "    model.load_weights(weight_path)\n",
    "\n",
    "    inference_model = Model(base_model.get_input_at(0), output=base_model.get_output_at(0))\n",
    "    inference_model.compile(loss=\"mse\", optimizer=Adam(0.000001))\n",
    "    print(inference_model.summary())\n",
    "\n",
    "    return inference_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_resize(filepath):\n",
    "    im = Image.open((filepath)).convert('RGB')\n",
    "    im = im.resize(input_shape)\n",
    "    im_array = np.array(im, dtype=\"uint8\")[..., ::-1]\n",
    "    return np.array(im_array / (np.max(im_array) + 0.001), dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_greyscale(img, p):\n",
    "    if np.random.uniform(0, 1) < p:\n",
    "        temp = np.dot(img[...,:3], [0.299, 0.587, 0.114])\n",
    "        temp = np.stack((temp,) * 3, -1)\n",
    "        return temp\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment(im_array):\n",
    "    #flip image\n",
    "    if np.random.uniform(0, 1) > 0.5:\n",
    "        im_array = np.fliplr(im_array)\n",
    "        \n",
    "    #FINAL add noise\n",
    "    im_array = random_rotation(im_array, rg=30, row_axis=0, col_axis=1, channel_axis=2, fill_mode='nearest')\n",
    "    #im_array = random_shift(im_array, wrg=0.1, hrg=0.3, row_axis=0, col_axis=1, channel_axis=2, fill_mode='nearest')\n",
    "    im_array = random_shear(im_array, intensity=10, row_axis=0, col_axis=1, channel_axis=2, fill_mode='nearest')\n",
    "    im_array = random_zoom(im_array, zoom_range=(1, 2.0), row_axis=0, col_axis=1, channel_axis=2, fill_mode='nearest')\n",
    "    im_array = random_greyscale(im_array, 0.4)    \n",
    "    \n",
    "    return im_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen(triplet_gen):\n",
    "    while True:\n",
    "        list_positive_examples_1 = []\n",
    "        list_negative_examples = []\n",
    "        list_positive_examples_2 = []\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            positive_example_1, negative_example, positive_example_2 = triplet_gen.get_sample()\n",
    "            positive_example_1_img, negative_example_img, positive_example_2_img = read_and_resize(base_path+positive_example_1), \\\n",
    "                                                                       read_and_resize(base_path+negative_example), \\\n",
    "                                                                       read_and_resize(base_path+positive_example_2)\n",
    "\n",
    "            positive_example_1_img, negative_example_img, positive_example_2_img = augment(positive_example_1_img), \\\n",
    "                                                                                   augment(negative_example_img), \\\n",
    "                                                                                   augment(positive_example_2_img)\n",
    "\n",
    "            list_positive_examples_1.append(positive_example_1_img)\n",
    "            list_negative_examples.append(negative_example_img)\n",
    "            list_positive_examples_2.append(positive_example_2_img)\n",
    "\n",
    "        list_positive_examples_1 = np.array(list_positive_examples_1)\n",
    "        list_negative_examples = np.array(list_negative_examples)\n",
    "        list_positive_examples_2 = np.array(list_positive_examples_2)\n",
    "        yield [list_positive_examples_1, list_negative_examples, list_positive_examples_2], np.ones(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(fpaths, batch=16):\n",
    "    i = 0\n",
    "    for path in fpaths:\n",
    "        if i == 0:\n",
    "            imgs = []\n",
    "            fnames = []\n",
    "        i += 1\n",
    "        img = read_and_resize(path)\n",
    "        imgs.append(img)\n",
    "        fnames.append(os.path.basename(path))\n",
    "        if i == batch:\n",
    "            i = 0\n",
    "            imgs = np.array(imgs)\n",
    "            yield fnames, imgs\n",
    "    if i < batch:\n",
    "        imgs = np.array(imgs)\n",
    "        yield fnames, imgs\n",
    "    raise StopIteration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/user/.local/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:1154: calling reduce_max (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /home/user/.local/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:2901: calling l2_normalize (from tensorflow.python.ops.nn_impl) with dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "dim is deprecated, use axis instead\n",
      "WARNING:tensorflow:From /home/user/.local/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:1188: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /home/user/.local/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:1290: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:16: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  app.launch_new_instance()\n",
      "/home/user/.local/lib/python3.5/site-packages/keras/legacy/layers.py:458: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name=name)\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:20: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"lo...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "positive_example_1 (InputLayer)  (None, 256, 256, 3)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "negative_example (InputLayer)    (None, 256, 256, 3)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "positive_example_2 (InputLayer)  (None, 256, 256, 3)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "base_model (Model)               (None, 50)            23690162    positive_example_1[0][0]         \n",
      "                                                                   negative_example[0][0]           \n",
      "                                                                   positive_example_2[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "loss (Merge)                     (None, 1)             0           base_model[1][0]                 \n",
      "                                                                   base_model[2][0]                 \n",
      "                                                                   base_model[3][0]                 \n",
      "====================================================================================================\n",
      "Total params: 23,690,162\n",
      "Trainable params: 23,637,042\n",
      "Non-trainable params: 53,120\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/300\n",
      "Epoch 00000: val_loss improved from inf to 0.47218, saving model to triplet_model_with_data_aug_weights.best.hdf5\n",
      "297s - loss: 0.4878 - val_loss: 0.4722\n",
      "Epoch 2/300\n",
      "Epoch 00001: val_loss improved from 0.47218 to 0.46092, saving model to triplet_model_with_data_aug_weights.best.hdf5\n",
      "269s - loss: 0.4872 - val_loss: 0.4609\n",
      "Epoch 3/300\n",
      "Epoch 00002: val_loss improved from 0.46092 to 0.45617, saving model to triplet_model_with_data_aug_weights.best.hdf5\n",
      "268s - loss: 0.4861 - val_loss: 0.4562\n",
      "Epoch 4/300\n",
      "Epoch 00003: val_loss did not improve\n",
      "266s - loss: 0.4855 - val_loss: 0.4602\n",
      "Epoch 5/300\n",
      "Epoch 00004: val_loss improved from 0.45617 to 0.45538, saving model to triplet_model_with_data_aug_weights.best.hdf5\n",
      "267s - loss: 0.4842 - val_loss: 0.4554\n",
      "Epoch 6/300\n",
      "Epoch 00005: val_loss improved from 0.45538 to 0.44975, saving model to triplet_model_with_data_aug_weights.best.hdf5\n",
      "268s - loss: 0.4836 - val_loss: 0.4498\n",
      "Epoch 7/300\n",
      "Epoch 00006: val_loss improved from 0.44975 to 0.44668, saving model to triplet_model_with_data_aug_weights.best.hdf5\n",
      "267s - loss: 0.4808 - val_loss: 0.4467\n",
      "Epoch 8/300\n",
      "Epoch 00007: val_loss improved from 0.44668 to 0.44128, saving model to triplet_model_with_data_aug_weights.best.hdf5\n",
      "268s - loss: 0.4781 - val_loss: 0.4413\n",
      "Epoch 9/300\n",
      "Epoch 00008: val_loss improved from 0.44128 to 0.43433, saving model to triplet_model_with_data_aug_weights.best.hdf5\n",
      "267s - loss: 0.4755 - val_loss: 0.4343\n",
      "Epoch 10/300\n",
      "Epoch 00009: val_loss improved from 0.43433 to 0.42987, saving model to triplet_model_with_data_aug_weights.best.hdf5\n",
      "267s - loss: 0.4734 - val_loss: 0.4299\n",
      "Epoch 11/300\n",
      "Epoch 00010: val_loss improved from 0.42987 to 0.42307, saving model to triplet_model_with_data_aug_weights.best.hdf5\n",
      "268s - loss: 0.4708 - val_loss: 0.4231\n",
      "Epoch 12/300\n",
      "Epoch 00011: val_loss improved from 0.42307 to 0.41902, saving model to triplet_model_with_data_aug_weights.best.hdf5\n",
      "268s - loss: 0.4668 - val_loss: 0.4190\n",
      "Epoch 13/300\n",
      "Epoch 00012: val_loss improved from 0.41902 to 0.40822, saving model to triplet_model_with_data_aug_weights.best.hdf5\n",
      "268s - loss: 0.4632 - val_loss: 0.4082\n",
      "Epoch 14/300\n",
      "Epoch 00013: val_loss improved from 0.40822 to 0.39793, saving model to triplet_model_with_data_aug_weights.best.hdf5\n",
      "268s - loss: 0.4566 - val_loss: 0.3979\n",
      "Epoch 15/300\n",
      "Epoch 00014: val_loss did not improve\n",
      "267s - loss: 0.4510 - val_loss: 0.4042\n",
      "Epoch 16/300\n",
      "Epoch 00015: val_loss improved from 0.39793 to 0.39454, saving model to triplet_model_with_data_aug_weights.best.hdf5\n",
      "267s - loss: 0.4459 - val_loss: 0.3945\n",
      "Epoch 17/300\n",
      "Epoch 00016: val_loss improved from 0.39454 to 0.38994, saving model to triplet_model_with_data_aug_weights.best.hdf5\n",
      "269s - loss: 0.4409 - val_loss: 0.3899\n",
      "Epoch 18/300\n",
      "Epoch 00017: val_loss improved from 0.38994 to 0.37338, saving model to triplet_model_with_data_aug_weights.best.hdf5\n",
      "268s - loss: 0.4306 - val_loss: 0.3734\n",
      "Epoch 19/300\n",
      "Epoch 00018: val_loss improved from 0.37338 to 0.37067, saving model to triplet_model_with_data_aug_weights.best.hdf5\n",
      "268s - loss: 0.4259 - val_loss: 0.3707\n",
      "Epoch 20/300\n",
      "Epoch 00019: val_loss improved from 0.37067 to 0.35467, saving model to triplet_model_with_data_aug_weights.best.hdf5\n",
      "268s - loss: 0.4198 - val_loss: 0.3547\n",
      "Epoch 21/300\n",
      "Epoch 00020: val_loss did not improve\n",
      "266s - loss: 0.4118 - val_loss: 0.3636\n",
      "Epoch 22/300\n",
      "Epoch 00021: val_loss did not improve\n",
      "267s - loss: 0.4106 - val_loss: 0.3609\n",
      "Epoch 23/300\n",
      "Epoch 00022: val_loss improved from 0.35467 to 0.34596, saving model to triplet_model_with_data_aug_weights.best.hdf5\n",
      "267s - loss: 0.4032 - val_loss: 0.3460\n",
      "Epoch 24/300\n",
      "Epoch 00023: val_loss did not improve\n",
      "267s - loss: 0.4005 - val_loss: 0.3554\n",
      "Epoch 25/300\n",
      "Epoch 00024: val_loss did not improve\n",
      "267s - loss: 0.3988 - val_loss: 0.3540\n",
      "Epoch 26/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done fitting\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00025: val_loss did not improve\n",
      "266s - loss: 0.3945 - val_loss: 0.3461\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('../dataset/train.csv')\n",
    "train, test = train_test_split(data, test_size=0.3, shuffle=True, random_state=1337)\n",
    "file_id_mapping_train = {k: v for k, v in zip(train.Image.values, train.Id.values)}\n",
    "file_id_mapping_test = {k: v for k, v in zip(test.Image.values, test.Id.values)}\n",
    "train_gen = sample_gen(file_id_mapping_train)\n",
    "test_gen = sample_gen(file_id_mapping_test)\n",
    "\n",
    "# Prepare the test triplets\n",
    "model = build_model()\n",
    "#model.load_weights(file_path)\n",
    "\n",
    "callbacks_list = []\n",
    "callbacks_list.append(ModelCheckpoint(file_path, monitor='val_loss', verbose=1, save_best_only=True, mode='min'))\n",
    "callbacks_list.append(EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=2))\n",
    "epochs = 300\n",
    "history = model.fit_generator(gen(train_gen),\n",
    "                              validation_data=gen(test_gen),\n",
    "                              epochs=epochs,\n",
    "                              verbose=2,\n",
    "                              workers=1,\n",
    "                              callbacks=callbacks_list,\n",
    "                              steps_per_epoch=300,\n",
    "                              validation_steps=30)\n",
    "                              \n",
    "print(\"Done fitting\\n\", file=sys.stderr, flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:16: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  app.launch_new_instance()\n",
      "/home/user/.local/lib/python3.5/site-packages/keras/legacy/layers.py:458: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name=name)\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:20: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"lo...)`\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:25: UserWarning: Update your `Model` call to the Keras 2 API: `Model(Tensor(\"in..., outputs=Tensor(\"la...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_2 (InputLayer)             (None, None, None, 3) 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                   (None, None, None, 64 9472        input_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)    (None, None, None, 64 256         conv1[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "activation_50 (Activation)       (None, None, None, 64 0           bn_conv1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)   (None, None, None, 64 0           activation_50[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)          (None, None, None, 64 4160        max_pooling2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizatio (None, None, None, 64 256         res2a_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_51 (Activation)       (None, None, None, 64 0           bn2a_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)          (None, None, None, 64 36928       activation_51[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizatio (None, None, None, 64 256         res2a_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_52 (Activation)       (None, None, None, 64 0           bn2a_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)          (None, None, None, 25 16640       activation_52[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)           (None, None, None, 25 16640       max_pooling2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizatio (None, None, None, 25 1024        res2a_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalization (None, None, None, 25 1024        res2a_branch1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "add_17 (Add)                     (None, None, None, 25 0           bn2a_branch2c[0][0]              \n",
      "                                                                   bn2a_branch1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_53 (Activation)       (None, None, None, 25 0           add_17[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)          (None, None, None, 64 16448       activation_53[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizatio (None, None, None, 64 256         res2b_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_54 (Activation)       (None, None, None, 64 0           bn2b_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)          (None, None, None, 64 36928       activation_54[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizatio (None, None, None, 64 256         res2b_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_55 (Activation)       (None, None, None, 64 0           bn2b_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)          (None, None, None, 25 16640       activation_55[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizatio (None, None, None, 25 1024        res2b_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "add_18 (Add)                     (None, None, None, 25 0           bn2b_branch2c[0][0]              \n",
      "                                                                   activation_53[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_56 (Activation)       (None, None, None, 25 0           add_18[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)          (None, None, None, 64 16448       activation_56[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizatio (None, None, None, 64 256         res2c_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_57 (Activation)       (None, None, None, 64 0           bn2c_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)          (None, None, None, 64 36928       activation_57[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizatio (None, None, None, 64 256         res2c_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_58 (Activation)       (None, None, None, 64 0           bn2c_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)          (None, None, None, 25 16640       activation_58[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizatio (None, None, None, 25 1024        res2c_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "add_19 (Add)                     (None, None, None, 25 0           bn2c_branch2c[0][0]              \n",
      "                                                                   activation_56[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_59 (Activation)       (None, None, None, 25 0           add_19[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)          (None, None, None, 12 32896       activation_59[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizatio (None, None, None, 12 512         res3a_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_60 (Activation)       (None, None, None, 12 0           bn3a_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)          (None, None, None, 12 147584      activation_60[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizatio (None, None, None, 12 512         res3a_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_61 (Activation)       (None, None, None, 12 0           bn3a_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)          (None, None, None, 51 66048       activation_61[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)           (None, None, None, 51 131584      activation_59[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizatio (None, None, None, 51 2048        res3a_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalization (None, None, None, 51 2048        res3a_branch1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "add_20 (Add)                     (None, None, None, 51 0           bn3a_branch2c[0][0]              \n",
      "                                                                   bn3a_branch1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_62 (Activation)       (None, None, None, 51 0           add_20[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)          (None, None, None, 12 65664       activation_62[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizatio (None, None, None, 12 512         res3b_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_63 (Activation)       (None, None, None, 12 0           bn3b_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)          (None, None, None, 12 147584      activation_63[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizatio (None, None, None, 12 512         res3b_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_64 (Activation)       (None, None, None, 12 0           bn3b_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)          (None, None, None, 51 66048       activation_64[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizatio (None, None, None, 51 2048        res3b_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "add_21 (Add)                     (None, None, None, 51 0           bn3b_branch2c[0][0]              \n",
      "                                                                   activation_62[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_65 (Activation)       (None, None, None, 51 0           add_21[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)          (None, None, None, 12 65664       activation_65[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizatio (None, None, None, 12 512         res3c_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_66 (Activation)       (None, None, None, 12 0           bn3c_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)          (None, None, None, 12 147584      activation_66[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizatio (None, None, None, 12 512         res3c_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_67 (Activation)       (None, None, None, 12 0           bn3c_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)          (None, None, None, 51 66048       activation_67[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizatio (None, None, None, 51 2048        res3c_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "add_22 (Add)                     (None, None, None, 51 0           bn3c_branch2c[0][0]              \n",
      "                                                                   activation_65[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_68 (Activation)       (None, None, None, 51 0           add_22[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)          (None, None, None, 12 65664       activation_68[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizatio (None, None, None, 12 512         res3d_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_69 (Activation)       (None, None, None, 12 0           bn3d_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)          (None, None, None, 12 147584      activation_69[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizatio (None, None, None, 12 512         res3d_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_70 (Activation)       (None, None, None, 12 0           bn3d_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)          (None, None, None, 51 66048       activation_70[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizatio (None, None, None, 51 2048        res3d_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "add_23 (Add)                     (None, None, None, 51 0           bn3d_branch2c[0][0]              \n",
      "                                                                   activation_68[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_71 (Activation)       (None, None, None, 51 0           add_23[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)          (None, None, None, 25 131328      activation_71[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizatio (None, None, None, 25 1024        res4a_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_72 (Activation)       (None, None, None, 25 0           bn4a_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)          (None, None, None, 25 590080      activation_72[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizatio (None, None, None, 25 1024        res4a_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_73 (Activation)       (None, None, None, 25 0           bn4a_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)          (None, None, None, 10 263168      activation_73[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)           (None, None, None, 10 525312      activation_71[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizatio (None, None, None, 10 4096        res4a_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalization (None, None, None, 10 4096        res4a_branch1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "add_24 (Add)                     (None, None, None, 10 0           bn4a_branch2c[0][0]              \n",
      "                                                                   bn4a_branch1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_74 (Activation)       (None, None, None, 10 0           add_24[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)          (None, None, None, 25 262400      activation_74[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizatio (None, None, None, 25 1024        res4b_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_75 (Activation)       (None, None, None, 25 0           bn4b_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)          (None, None, None, 25 590080      activation_75[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizatio (None, None, None, 25 1024        res4b_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_76 (Activation)       (None, None, None, 25 0           bn4b_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)          (None, None, None, 10 263168      activation_76[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizatio (None, None, None, 10 4096        res4b_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "add_25 (Add)                     (None, None, None, 10 0           bn4b_branch2c[0][0]              \n",
      "                                                                   activation_74[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_77 (Activation)       (None, None, None, 10 0           add_25[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)          (None, None, None, 25 262400      activation_77[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizatio (None, None, None, 25 1024        res4c_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_78 (Activation)       (None, None, None, 25 0           bn4c_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)          (None, None, None, 25 590080      activation_78[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizatio (None, None, None, 25 1024        res4c_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_79 (Activation)       (None, None, None, 25 0           bn4c_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)          (None, None, None, 10 263168      activation_79[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizatio (None, None, None, 10 4096        res4c_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "add_26 (Add)                     (None, None, None, 10 0           bn4c_branch2c[0][0]              \n",
      "                                                                   activation_77[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_80 (Activation)       (None, None, None, 10 0           add_26[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)          (None, None, None, 25 262400      activation_80[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizatio (None, None, None, 25 1024        res4d_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_81 (Activation)       (None, None, None, 25 0           bn4d_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)          (None, None, None, 25 590080      activation_81[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizatio (None, None, None, 25 1024        res4d_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_82 (Activation)       (None, None, None, 25 0           bn4d_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)          (None, None, None, 10 263168      activation_82[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizatio (None, None, None, 10 4096        res4d_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "add_27 (Add)                     (None, None, None, 10 0           bn4d_branch2c[0][0]              \n",
      "                                                                   activation_80[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_83 (Activation)       (None, None, None, 10 0           add_27[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)          (None, None, None, 25 262400      activation_83[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizatio (None, None, None, 25 1024        res4e_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_84 (Activation)       (None, None, None, 25 0           bn4e_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)          (None, None, None, 25 590080      activation_84[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizatio (None, None, None, 25 1024        res4e_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_85 (Activation)       (None, None, None, 25 0           bn4e_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)          (None, None, None, 10 263168      activation_85[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizatio (None, None, None, 10 4096        res4e_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "add_28 (Add)                     (None, None, None, 10 0           bn4e_branch2c[0][0]              \n",
      "                                                                   activation_83[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_86 (Activation)       (None, None, None, 10 0           add_28[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)          (None, None, None, 25 262400      activation_86[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizatio (None, None, None, 25 1024        res4f_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_87 (Activation)       (None, None, None, 25 0           bn4f_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)          (None, None, None, 25 590080      activation_87[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizatio (None, None, None, 25 1024        res4f_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_88 (Activation)       (None, None, None, 25 0           bn4f_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)          (None, None, None, 10 263168      activation_88[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizatio (None, None, None, 10 4096        res4f_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "add_29 (Add)                     (None, None, None, 10 0           bn4f_branch2c[0][0]              \n",
      "                                                                   activation_86[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_89 (Activation)       (None, None, None, 10 0           add_29[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)          (None, None, None, 51 524800      activation_89[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizatio (None, None, None, 51 2048        res5a_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_90 (Activation)       (None, None, None, 51 0           bn5a_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)          (None, None, None, 51 2359808     activation_90[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizatio (None, None, None, 51 2048        res5a_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_91 (Activation)       (None, None, None, 51 0           bn5a_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)          (None, None, None, 20 1050624     activation_91[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)           (None, None, None, 20 2099200     activation_89[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizatio (None, None, None, 20 8192        res5a_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalization (None, None, None, 20 8192        res5a_branch1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "add_30 (Add)                     (None, None, None, 20 0           bn5a_branch2c[0][0]              \n",
      "                                                                   bn5a_branch1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_92 (Activation)       (None, None, None, 20 0           add_30[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)          (None, None, None, 51 1049088     activation_92[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizatio (None, None, None, 51 2048        res5b_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_93 (Activation)       (None, None, None, 51 0           bn5b_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)          (None, None, None, 51 2359808     activation_93[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizatio (None, None, None, 51 2048        res5b_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_94 (Activation)       (None, None, None, 51 0           bn5b_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)          (None, None, None, 20 1050624     activation_94[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizatio (None, None, None, 20 8192        res5b_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "add_31 (Add)                     (None, None, None, 20 0           bn5b_branch2c[0][0]              \n",
      "                                                                   activation_92[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_95 (Activation)       (None, None, None, 20 0           add_31[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)          (None, None, None, 51 1049088     activation_95[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizatio (None, None, None, 51 2048        res5c_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_96 (Activation)       (None, None, None, 51 0           bn5c_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)          (None, None, None, 51 2359808     activation_96[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizatio (None, None, None, 51 2048        res5c_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_97 (Activation)       (None, None, None, 51 0           bn5c_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)          (None, None, None, 20 1050624     activation_97[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizatio (None, None, None, 20 8192        res5c_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "add_32 (Add)                     (None, None, None, 20 0           bn5c_branch2c[0][0]              \n",
      "                                                                   activation_95[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_98 (Activation)       (None, None, None, 20 0           add_32[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "avg_pool (AveragePooling2D)      (None, None, None, 20 0           activation_98[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "global_max_pooling2d_2 (GlobalMa (None, 2048)          0           avg_pool[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 2048)          0           global_max_pooling2d_2[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 50)            102450      dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)                (None, 50)            0           dense_2[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 23,690,162\n",
      "Trainable params: 23,637,042\n",
      "Non-trainable params: 53,120\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3248730964467005\n",
      "0.649746192893401\n",
      "0.9746192893401016\n",
      "1.299492385786802\n",
      "1.6243654822335025\n",
      "1.9492385786802031\n",
      "2.2741116751269037\n",
      "2.598984771573604\n",
      "2.9238578680203045\n",
      "3.248730964467005\n",
      "3.5736040609137056\n",
      "3.8984771573604062\n",
      "4.223350253807107\n",
      "4.548223350253807\n",
      "4.873096446700507\n",
      "5.197969543147208\n",
      "5.522842639593908\n",
      "5.847715736040609\n",
      "6.1725888324873095\n",
      "6.49746192893401\n",
      "6.82233502538071\n",
      "7.147208121827411\n",
      "7.472081218274111\n",
      "7.7969543147208125\n",
      "8.121827411167512\n",
      "8.446700507614214\n",
      "8.771573604060915\n",
      "9.096446700507615\n",
      "9.421319796954315\n",
      "9.746192893401014\n",
      "10.071065989847716\n",
      "10.395939086294415\n",
      "10.720812182741117\n",
      "11.045685279187817\n",
      "11.370558375634518\n",
      "11.695431472081218\n",
      "12.02030456852792\n",
      "12.345177664974619\n",
      "12.67005076142132\n",
      "12.99492385786802\n",
      "13.319796954314722\n",
      "13.64467005076142\n",
      "13.969543147208121\n",
      "14.294416243654823\n",
      "14.619289340101524\n",
      "14.944162436548222\n",
      "15.269035532994923\n",
      "15.593908629441625\n",
      "15.918781725888326\n",
      "16.243654822335024\n",
      "16.568527918781726\n",
      "16.893401015228427\n",
      "17.21827411167513\n",
      "17.54314720812183\n",
      "17.868020304568528\n",
      "18.19289340101523\n",
      "18.517766497461928\n",
      "18.84263959390863\n",
      "19.16751269035533\n",
      "19.49238578680203\n",
      "19.81725888324873\n",
      "20.14213197969543\n",
      "20.46700507614213\n",
      "20.79187817258883\n",
      "21.116751269035532\n",
      "21.441624365482234\n",
      "21.766497461928935\n",
      "22.091370558375633\n",
      "22.416243654822335\n",
      "22.741116751269036\n",
      "23.065989847715738\n",
      "23.390862944162436\n",
      "23.715736040609137\n",
      "24.04060913705584\n",
      "24.36548223350254\n",
      "24.690355329949238\n",
      "25.015228426395943\n",
      "25.34010152284264\n",
      "25.66497461928934\n",
      "25.98984771573604\n",
      "26.314720812182742\n",
      "26.639593908629443\n",
      "26.96446700507614\n",
      "27.28934010152284\n",
      "27.614213197969544\n",
      "27.939086294416242\n",
      "28.26395939086294\n",
      "28.588832487309645\n",
      "28.913705583756343\n",
      "29.238578680203048\n",
      "29.563451776649746\n",
      "29.888324873096444\n",
      "30.21319796954315\n",
      "30.538071065989847\n",
      "30.862944162436552\n",
      "31.18781725888325\n",
      "31.512690355329948\n",
      "31.837563451776653\n",
      "32.16243654822335\n",
      "32.48730964467005\n",
      "32.81218274111675\n",
      "33.13705583756345\n",
      "33.46192893401015\n",
      "33.786802030456855\n",
      "34.11167512690355\n",
      "34.43654822335026\n",
      "34.76142131979695\n",
      "35.08629441624366\n",
      "35.411167512690355\n",
      "35.736040609137056\n",
      "36.06091370558376\n",
      "36.38578680203046\n",
      "36.710659898477154\n",
      "37.035532994923855\n",
      "37.36040609137056\n",
      "37.68527918781726\n",
      "38.01015228426396\n",
      "38.33502538071066\n",
      "38.65989847715736\n",
      "38.98477157360406\n",
      "39.309644670050766\n",
      "39.63451776649746\n",
      "39.95939086294416\n",
      "40.28426395939086\n",
      "40.609137055837564\n",
      "40.93401015228426\n",
      "41.25888324873097\n",
      "41.58375634517766\n",
      "41.90862944162437\n",
      "42.233502538071065\n",
      "42.558375634517766\n",
      "42.88324873096447\n",
      "43.20812182741117\n",
      "43.53299492385787\n",
      "43.85786802030457\n",
      "44.18274111675127\n",
      "44.50761421319797\n",
      "44.83248730964467\n",
      "45.15736040609137\n",
      "45.48223350253807\n",
      "45.807106598984774\n",
      "46.131979695431475\n",
      "46.45685279187817\n",
      "46.78172588832487\n",
      "47.10659898477157\n",
      "47.431472081218274\n",
      "47.756345177664976\n",
      "48.08121827411168\n",
      "48.40609137055837\n",
      "48.73096446700508\n",
      "49.055837563451774\n",
      "49.380710659898476\n",
      "49.70558375634518\n",
      "50.030456852791886\n",
      "50.35532994923858\n",
      "50.68020304568528\n",
      "51.005076142131976\n",
      "51.32994923857868\n",
      "51.654822335025386\n",
      "51.97969543147208\n",
      "52.30456852791878\n",
      "52.629441624365484\n",
      "52.95431472081218\n",
      "53.27918781725889\n",
      "53.60406091370559\n",
      "53.92893401015228\n",
      "54.253807106598984\n",
      "54.57868020304568\n",
      "54.90355329949238\n",
      "55.22842639593909\n",
      "55.55329949238579\n",
      "55.878172588832484\n",
      "56.203045685279186\n",
      "56.52791878172588\n",
      "56.852791878172596\n",
      "57.17766497461929\n",
      "57.50253807106599\n",
      "57.827411167512686\n",
      "58.15228426395939\n",
      "58.477157360406096\n",
      "58.80203045685279\n",
      "59.12690355329949\n",
      "59.45177664974619\n",
      "59.77664974619289\n",
      "60.101522842639596\n",
      "60.4263959390863\n",
      "60.75126903553299\n",
      "61.076142131979694\n",
      "61.401015228426395\n",
      "61.725888324873104\n",
      "62.0507614213198\n",
      "62.3756345177665\n",
      "62.700507614213194\n",
      "63.025380710659896\n",
      "63.3502538071066\n",
      "63.675126903553306\n",
      "64.0\n",
      "64.3248730964467\n",
      "64.6497461928934\n",
      "64.9746192893401\n",
      "65.2994923857868\n",
      "65.6243654822335\n",
      "65.94923857868021\n",
      "66.2741116751269\n",
      "66.5989847715736\n",
      "66.9238578680203\n",
      "67.248730964467\n",
      "67.57360406091371\n",
      "67.8984771573604\n",
      "68.2233502538071\n",
      "68.5482233502538\n",
      "68.87309644670052\n",
      "69.19796954314721\n",
      "69.5228426395939\n",
      "69.84771573604061\n",
      "70.17258883248732\n",
      "70.49746192893402\n",
      "70.82233502538071\n",
      "71.1472081218274\n",
      "71.47208121827411\n",
      "71.79695431472081\n",
      "72.12182741116752\n",
      "72.44670050761421\n",
      "72.77157360406092\n",
      "73.09644670050761\n",
      "73.42131979695431\n",
      "73.74619289340102\n",
      "74.07106598984771\n",
      "74.39593908629442\n",
      "74.72081218274111\n",
      "75.04568527918781\n",
      "75.37055837563452\n",
      "75.69543147208122\n",
      "76.02030456852792\n",
      "76.34517766497461\n",
      "76.67005076142132\n",
      "76.99492385786803\n",
      "77.31979695431473\n",
      "77.64467005076142\n",
      "77.96954314720811\n",
      "78.29441624365482\n",
      "78.61928934010153\n",
      "78.94416243654823\n",
      "79.26903553299492\n",
      "79.59390862944163\n",
      "79.91878172588832\n",
      "80.24365482233502\n",
      "80.56852791878173\n",
      "80.89340101522843\n",
      "81.21827411167513\n",
      "81.54314720812182\n",
      "81.86802030456852\n",
      "82.19289340101523\n",
      "82.51776649746193\n",
      "82.84263959390863\n",
      "83.16751269035532\n",
      "83.49238578680203\n",
      "83.81725888324874\n",
      "84.14213197969544\n",
      "84.46700507614213\n",
      "84.79187817258882\n",
      "85.11675126903553\n",
      "85.44162436548224\n",
      "85.76649746192894\n",
      "86.09137055837563\n",
      "86.41624365482234\n",
      "86.74111675126903\n",
      "87.06598984771574\n",
      "87.39086294416244\n",
      "87.71573604060914\n",
      "88.04060913705584\n",
      "88.36548223350253\n",
      "88.69035532994923\n",
      "89.01522842639594\n",
      "89.34010152284264\n",
      "89.66497461928934\n",
      "89.98984771573603\n",
      "90.31472081218274\n",
      "90.63959390862945\n",
      "90.96446700507614\n",
      "91.28934010152284\n",
      "91.61421319796955\n",
      "91.93908629441624\n",
      "92.26395939086295\n",
      "92.58883248730965\n",
      "92.91370558375634\n",
      "93.23857868020305\n",
      "93.56345177664974\n",
      "93.88832487309645\n",
      "94.21319796954315\n",
      "94.53807106598985\n",
      "94.86294416243655\n",
      "95.18781725888324\n",
      "95.51269035532995\n",
      "95.83756345177665\n",
      "96.16243654822335\n",
      "96.48730964467005\n",
      "96.81218274111674\n",
      "97.13705583756345\n",
      "97.46192893401016\n",
      "97.78680203045685\n",
      "98.11167512690355\n",
      "98.43654822335026\n",
      "98.76142131979695\n",
      "99.08629441624366\n",
      "99.41116751269035\n",
      "99.73604060913705\n",
      "100.06091370558377\n",
      "0.20499679692504805\n",
      "0.4099935938500961\n",
      "0.6149903907751442\n",
      "0.8199871877001922\n",
      "1.0249839846252402\n",
      "1.2299807815502883\n",
      "1.4349775784753362\n",
      "1.6399743754003844\n",
      "1.8449711723254325\n",
      "2.0499679692504804\n",
      "2.2549647661755285\n",
      "2.4599615631005767\n",
      "2.6649583600256244\n",
      "2.8699551569506725\n",
      "3.074951953875721\n",
      "3.2799487508007688\n",
      "3.4849455477258164\n",
      "3.689942344650865\n",
      "3.8949391415759127\n",
      "4.099935938500961\n",
      "4.304932735426009\n",
      "4.509929532351057\n",
      "4.714926329276105\n",
      "4.919923126201153\n",
      "5.1249199231262015\n",
      "5.329916720051249\n",
      "5.534913516976298\n",
      "5.739910313901345\n",
      "5.944907110826393\n",
      "6.149903907751442\n",
      "6.3549007046764885\n",
      "6.5598975016015375\n",
      "6.764894298526586\n",
      "6.969891095451633\n",
      "7.174887892376682\n",
      "7.37988468930173\n",
      "7.584881486226777\n",
      "7.789878283151825\n",
      "7.994875080076874\n",
      "8.199871877001922\n",
      "8.40486867392697\n",
      "8.609865470852018\n",
      "8.814862267777066\n",
      "9.019859064702114\n",
      "9.224855861627162\n",
      "9.42985265855221\n",
      "9.634849455477259\n",
      "9.839846252402307\n",
      "10.044843049327353\n",
      "10.249839846252403\n",
      "10.454836643177451\n",
      "10.659833440102497\n",
      "10.864830237027547\n",
      "11.069827033952595\n",
      "11.274823830877642\n",
      "11.47982062780269\n",
      "11.68481742472774\n",
      "11.889814221652786\n",
      "12.094811018577834\n",
      "12.299807815502884\n",
      "12.50480461242793\n",
      "12.709801409352977\n",
      "12.914798206278027\n",
      "13.119795003203075\n",
      "13.324791800128121\n",
      "13.529788597053171\n",
      "13.73478539397822\n",
      "13.939782190903266\n",
      "14.144778987828316\n",
      "14.349775784753364\n",
      "14.55477258167841\n",
      "14.75976937860346\n",
      "14.964766175528506\n",
      "15.169762972453555\n",
      "15.374759769378604\n",
      "15.57975656630365\n",
      "15.784753363228699\n",
      "15.989750160153749\n",
      "16.194746957078795\n",
      "16.399743754003843\n",
      "16.60474055092889\n",
      "16.80973734785394\n",
      "17.014734144778988\n",
      "17.219730941704036\n",
      "17.424727738629084\n",
      "17.629724535554132\n",
      "17.83472133247918\n",
      "18.03971812940423\n",
      "18.244714926329276\n",
      "18.449711723254325\n",
      "18.654708520179373\n",
      "18.85970531710442\n",
      "19.06470211402947\n",
      "19.269698910954517\n",
      "19.47469570787956\n",
      "19.679692504804613\n",
      "19.88468930172966\n",
      "20.089686098654706\n",
      "20.294682895579758\n",
      "20.499679692504806\n",
      "20.70467648942985\n",
      "20.909673286354902\n",
      "21.11467008327995\n",
      "21.319666880204995\n",
      "21.524663677130047\n",
      "21.729660474055095\n",
      "21.93465727098014\n",
      "22.13965406790519\n",
      "22.344650864830236\n",
      "22.549647661755284\n",
      "22.754644458680335\n",
      "22.95964125560538\n",
      "23.164638052530428\n",
      "23.36963484945548\n",
      "23.574631646380524\n",
      "23.779628443305572\n",
      "23.984625240230624\n",
      "24.18962203715567\n",
      "24.394618834080717\n",
      "24.59961563100577\n",
      "24.804612427930813\n",
      "25.00960922485586\n",
      "25.21460602178091\n",
      "25.419602818705954\n",
      "25.624599615631006\n",
      "25.829596412556054\n",
      "26.0345932094811\n",
      "26.23959000640615\n",
      "26.444586803331198\n",
      "26.649583600256243\n",
      "26.854580397181294\n",
      "27.059577194106343\n",
      "27.264573991031387\n",
      "27.46957078795644\n",
      "27.674567584881487\n",
      "27.87956438180653\n",
      "28.084561178731583\n",
      "28.28955797565663\n",
      "28.494554772581676\n",
      "28.699551569506728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.904548366431776\n",
      "29.10954516335682\n",
      "29.314541960281872\n",
      "29.51953875720692\n",
      "29.724535554131965\n",
      "29.929532351057013\n",
      "30.134529147982065\n",
      "30.33952594490711\n",
      "30.544522741832157\n",
      "30.74951953875721\n",
      "30.954516335682253\n",
      "31.1595131326073\n",
      "31.364509929532353\n",
      "31.569506726457398\n",
      "31.774503523382446\n",
      "31.979500320307498\n",
      "32.18449711723254\n",
      "32.38949391415759\n",
      "32.59449071108264\n",
      "32.79948750800769\n",
      "33.00448430493274\n",
      "33.20948110185778\n",
      "33.41447789878283\n",
      "33.61947469570788\n",
      "33.82447149263293\n",
      "34.029468289557975\n",
      "34.23446508648303\n",
      "34.43946188340807\n",
      "34.644458680333116\n",
      "34.84945547725817\n",
      "35.05445227418322\n",
      "35.259449071108264\n",
      "35.46444586803331\n",
      "35.66944266495836\n",
      "35.874439461883405\n",
      "36.07943625880846\n",
      "36.28443305573351\n",
      "36.48942985265855\n",
      "36.6944266495836\n",
      "36.89942344650865\n",
      "37.104420243433694\n",
      "37.309417040358746\n",
      "37.5144138372838\n",
      "37.71941063420884\n",
      "37.924407431133886\n",
      "38.12940422805894\n",
      "38.33440102498398\n",
      "38.539397821909034\n",
      "38.744394618834086\n",
      "38.94939141575912\n",
      "39.154388212684175\n",
      "39.35938500960923\n",
      "39.56438180653427\n",
      "39.76937860345932\n",
      "39.97437540038437\n",
      "40.17937219730941\n",
      "40.384368994234464\n",
      "40.589365791159516\n",
      "40.79436258808456\n",
      "40.99935938500961\n",
      "41.204356181934656\n",
      "41.4093529788597\n",
      "41.61434977578475\n",
      "41.819346572709804\n",
      "42.02434336963485\n",
      "42.2293401665599\n",
      "42.434336963484945\n",
      "42.63933376040999\n",
      "42.84433055733504\n",
      "43.04932735426009\n",
      "43.25432415118514\n",
      "43.45932094811019\n",
      "43.664317745035234\n",
      "43.86931454196028\n",
      "44.07431133888533\n",
      "44.27930813581038\n",
      "44.48430493273543\n",
      "44.68930172966047\n",
      "44.89429852658552\n",
      "45.09929532351057\n",
      "45.30429212043562\n",
      "45.50928891736067\n",
      "45.714285714285715\n",
      "45.91928251121076\n",
      "46.12427930813581\n",
      "46.329276105060856\n",
      "46.53427290198591\n",
      "46.73926969891096\n",
      "46.944266495836004\n",
      "47.14926329276105\n",
      "47.3542600896861\n",
      "47.559256886611145\n",
      "47.7642536835362\n",
      "47.96925048046125\n",
      "48.17424727738629\n",
      "48.37924407431134\n",
      "48.58424087123639\n",
      "48.789237668161434\n",
      "48.994234465086485\n",
      "49.19923126201154\n",
      "49.404228058936575\n",
      "49.609224855861626\n",
      "49.81422165278668\n",
      "50.01921844971172\n",
      "50.224215246636774\n",
      "50.42921204356182\n",
      "50.63420884048687\n",
      "50.83920563741191\n",
      "51.04420243433696\n",
      "51.24919923126201\n",
      "51.45419602818706\n",
      "51.65919282511211\n",
      "51.86418962203716\n",
      "52.0691864189622\n",
      "52.27418321588725\n",
      "52.4791800128123\n",
      "52.68417680973735\n",
      "52.889173606662396\n",
      "53.09417040358745\n",
      "53.299167200512485\n",
      "53.50416399743754\n",
      "53.70916079436259\n",
      "53.91415759128763\n",
      "54.119154388212685\n",
      "54.32415118513774\n",
      "54.529147982062774\n",
      "54.734144778987826\n",
      "54.93914157591288\n",
      "55.14413837283792\n",
      "55.349135169762974\n",
      "55.554131966688026\n",
      "55.75912876361306\n",
      "55.964125560538115\n",
      "56.169122357463166\n",
      "56.37411915438821\n",
      "56.57911595131326\n",
      "56.784112748238314\n",
      "56.98910954516335\n",
      "57.1941063420884\n",
      "57.399103139013455\n",
      "57.6040999359385\n",
      "57.80909673286355\n",
      "58.0140935297886\n",
      "58.21909032671364\n",
      "58.42408712363869\n",
      "58.629083920563744\n",
      "58.83408071748879\n",
      "59.03907751441384\n",
      "59.24407431133889\n",
      "59.44907110826393\n",
      "59.65406790518898\n",
      "59.859064702114026\n",
      "60.06406149903908\n",
      "60.26905829596413\n",
      "60.47405509288918\n",
      "60.67905188981422\n",
      "60.88404868673927\n",
      "61.089045483664314\n",
      "61.294042280589366\n",
      "61.49903907751442\n",
      "61.70403587443947\n",
      "61.90903267136451\n",
      "62.11402946828956\n",
      "62.3190262652146\n",
      "62.524023062139655\n",
      "62.72901985906471\n",
      "62.93401665598976\n",
      "63.139013452914796\n",
      "63.34401024983984\n",
      "63.54900704676489\n",
      "63.754003843689944\n",
      "63.959000640614995\n",
      "64.16399743754005\n",
      "64.36899423446508\n",
      "64.57399103139014\n",
      "64.77898782831518\n",
      "64.98398462524023\n",
      "65.18898142216528\n",
      "65.39397821909033\n",
      "65.59897501601537\n",
      "65.80397181294042\n",
      "66.00896860986548\n",
      "66.21396540679052\n",
      "66.41896220371557\n",
      "66.62395900064062\n",
      "66.82895579756565\n",
      "67.03395259449071\n",
      "67.23894939141576\n",
      "67.4439461883408\n",
      "67.64894298526586\n",
      "67.8539397821909\n",
      "68.05893657911595\n",
      "68.263933376041\n",
      "68.46893017296605\n",
      "68.6739269698911\n",
      "68.87892376681614\n",
      "69.0839205637412\n",
      "69.28891736066623\n",
      "69.49391415759129\n",
      "69.69891095451634\n",
      "69.90390775144138\n",
      "70.10890454836644\n",
      "70.31390134529148\n",
      "70.51889814221653\n",
      "70.72389493914157\n",
      "70.92889173606662\n",
      "71.13388853299168\n",
      "71.33888532991672\n",
      "71.54388212684178\n",
      "71.74887892376681\n",
      "71.95387572069187\n",
      "72.15887251761691\n",
      "72.36386931454196\n",
      "72.56886611146702\n",
      "72.77386290839206\n",
      "72.9788597053171\n",
      "73.18385650224215\n",
      "73.3888532991672\n",
      "73.59385009609225\n",
      "73.7988468930173\n",
      "74.00384368994236\n",
      "74.20884048686739\n",
      "74.41383728379243\n",
      "74.61883408071749\n",
      "74.82383087764254\n",
      "75.0288276745676\n",
      "75.23382447149262\n",
      "75.43882126841768\n",
      "75.64381806534273\n",
      "75.84881486226777\n",
      "76.05381165919283\n",
      "76.25880845611788\n",
      "76.46380525304292\n",
      "76.66880204996797\n",
      "76.87379884689301\n",
      "77.07879564381807\n",
      "77.28379244074311\n",
      "77.48878923766817\n",
      "77.6937860345932\n",
      "77.89878283151825\n",
      "78.1037796284433\n",
      "78.30877642536835\n",
      "78.51377322229341\n",
      "78.71877001921845\n",
      "78.9237668161435\n",
      "79.12876361306854\n",
      "79.33376040999359\n",
      "79.53875720691865\n",
      "79.74375400384369\n",
      "79.94875080076874\n",
      "80.15374759769378\n",
      "80.35874439461882\n",
      "80.56374119154388\n",
      "80.76873798846893\n",
      "80.97373478539399\n",
      "81.17873158231903\n",
      "81.38372837924408\n",
      "81.58872517616912\n",
      "81.79372197309416\n",
      "81.99871877001922\n",
      "82.20371556694427\n",
      "82.40871236386931\n",
      "82.61370916079436\n",
      "82.8187059577194\n",
      "83.02370275464446\n",
      "83.2286995515695\n",
      "83.43369634849455\n",
      "83.63869314541961\n",
      "83.84368994234464\n",
      "84.0486867392697\n",
      "84.25368353619474\n",
      "84.4586803331198\n",
      "84.66367713004485\n",
      "84.86867392696989\n",
      "85.07367072389494\n",
      "85.27866752081998\n",
      "85.48366431774504\n",
      "85.68866111467008\n",
      "85.89365791159513\n",
      "86.09865470852019\n",
      "86.30365150544522\n",
      "86.50864830237028\n",
      "86.71364509929532\n",
      "86.91864189622038\n",
      "87.12363869314542\n",
      "87.32863549007047\n",
      "87.53363228699551\n",
      "87.73862908392056\n",
      "87.94362588084562\n",
      "88.14862267777066\n",
      "88.3536194746957\n",
      "88.55861627162076\n",
      "88.7636130685458\n",
      "88.96860986547085\n",
      "89.1736066623959\n",
      "89.37860345932094\n",
      "89.583600256246\n",
      "89.78859705317105\n",
      "89.99359385009609\n",
      "90.19859064702113\n",
      "90.4035874439462\n",
      "90.60858424087124\n",
      "90.81358103779628\n",
      "91.01857783472134\n",
      "91.22357463164637\n",
      "91.42857142857143\n",
      "91.63356822549648\n",
      "91.83856502242152\n",
      "92.04356181934658\n",
      "92.24855861627162\n",
      "92.45355541319667\n",
      "92.65855221012171\n",
      "92.86354900704677\n",
      "93.06854580397182\n",
      "93.27354260089686\n",
      "93.47853939782192\n",
      "93.68353619474695\n",
      "93.88853299167201\n",
      "94.09352978859705\n",
      "94.2985265855221\n",
      "94.50352338244716\n",
      "94.7085201793722\n",
      "94.91351697629725\n",
      "95.11851377322229\n",
      "95.32351057014733\n",
      "95.5285073670724\n",
      "95.73350416399744\n",
      "95.9385009609225\n",
      "96.14349775784753\n",
      "96.34849455477259\n",
      "96.55349135169763\n",
      "96.75848814862267\n",
      "96.96348494554773\n",
      "97.16848174247278\n",
      "97.37347853939782\n",
      "97.57847533632287\n",
      "97.78347213324791\n",
      "97.98846893017297\n",
      "98.19346572709802\n",
      "98.39846252402307\n",
      "98.6034593209481\n",
      "98.80845611787315\n",
      "99.01345291479821\n",
      "99.21844971172325\n",
      "99.42344650864831\n",
      "99.62844330557336\n",
      "99.8334401024984\n",
      "100.03843689942344\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "data = pd.read_csv('train.csv')\n",
    "\n",
    "file_id_mapping = {k: v for k, v in zip(data.Image.values, data.Id.values)}\n",
    "\n",
    "inference_model = build_inference_model()\n",
    "\n",
    "train_files = glob.glob(\"../dataset/train/*.jpg\")\n",
    "test_files = glob.glob(\"../dataset/test/*.jpg\")\n",
    "\n",
    "#getting train data embedding\n",
    "train_preds = []\n",
    "train_file_names = []\n",
    "i = 1\n",
    "for fnames, imgs in data_generator(train_files, batch=32):\n",
    "    print(i*32/len(train_files)*100)\n",
    "    i += 1\n",
    "    predicts = inference_model.predict(imgs)\n",
    "    predicts = predicts.tolist()\n",
    "    train_preds += predicts\n",
    "    train_file_names += fnames\n",
    "train_preds = np.array(train_preds)\n",
    "\n",
    "#getting test data embedding\n",
    "test_preds = []\n",
    "test_file_names = []\n",
    "i = 1\n",
    "for fnames, imgs in data_generator(test_files, batch=32):\n",
    "    print(i * 32 / len(test_files) * 100)\n",
    "    i += 1\n",
    "    predicts = inference_model.predict(imgs)\n",
    "    predicts = predicts.tolist()\n",
    "    test_preds += predicts\n",
    "    test_file_names += fnames\n",
    "test_preds = np.array(test_preds)\n",
    "\n",
    "neigh = NearestNeighbors(n_neighbors=6)\n",
    "neigh.fit(train_preds)\n",
    "#distances, neighbors = neigh.kneighbors(train_preds)\n",
    "#print(distances, neighbors)\n",
    "\n",
    "distances_test, neighbors_test = neigh.kneighbors(test_preds)\n",
    "\n",
    "distances_test, neighbors_test = distances_test.tolist(), neighbors_test.tolist()\n",
    "\n",
    "preds_str = []\n",
    "\n",
    "for filepath, distance, neighbour_ in zip(test_file_names, distances_test, neighbors_test):\n",
    "    sample_result = []\n",
    "    sample_classes = []\n",
    "    for d, n in zip(distance, neighbour_):\n",
    "        train_file = train_files[n].split(os.sep)[-1]\n",
    "        class_train = file_id_mapping[train_file]\n",
    "        sample_classes.append(class_train)\n",
    "        sample_result.append((class_train, d))\n",
    "\n",
    "    if \"new_whale\" not in sample_classes:\n",
    "        sample_result.append((\"new_whale\", 0.1))\n",
    "    sample_result.sort(key=lambda x: x[1])\n",
    "    sample_result = sample_result[:5]\n",
    "    preds_str.append(\" \".join([x[0] for x in sample_result]))\n",
    "\n",
    "df = pd.DataFrame(preds_str, columns=[\"Id\"])\n",
    "df['Image'] = [x.split(os.sep)[-1] for x in test_file_names]\n",
    "df.to_csv(str(epochs) + \"_epoch_with_data_aug.csv\", index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
